{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52af13c7",
   "metadata": {},
   "source": [
    "# **Quantum-Classical Parameter Mapping**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04b6c61d",
   "metadata": {},
   "source": [
    "This version is ideal for getting results without having to simulate all the tests and checks and scroll through the explanation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "import math\n",
    "import re\n",
    "from numba import njit\n",
    "from itertools import product\n",
    "from scipy.linalg import kron\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "from numba.typed import List"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b1dc355",
   "metadata": {},
   "source": [
    "## **Implementation of toy dynamics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  CONVERTING SPIN <-> BINARY FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "@njit\n",
    "def index_to_spin_state(s_idx: int, N: int) -> np.ndarray:\n",
    "    \"\"\"Convert an index to a spin state.\"\"\"\n",
    "    s = np.zeros((N,), dtype=np.int64)\n",
    "    for i in range(N):\n",
    "        # get the ith bit of s_idx.\n",
    "        bit = (s_idx >> i) & 1\n",
    "        # convert the bit to a spin (-1 or 1).\n",
    "        s[N - 1 - i] = bit * 2 - 1\n",
    "    return s\n",
    "\n",
    "@njit\n",
    "def spin_state_to_index(s: np.ndarray) -> int:\n",
    "    \"\"\"Convert a spin state to an index.\"\"\"\n",
    "    N = len(s)\n",
    "    s_idx = 0\n",
    "    for i in range(N):\n",
    "        # convert the spin to a bit (0 or 1).\n",
    "        bit = (s[i] + 1) // 2\n",
    "        # set the ith bit of s_idx.\n",
    "        s_idx |= bit << (N - 1 - i)\n",
    "    return s_idx\n",
    "\n",
    "@njit\n",
    "def bits_flipped_indices(s_idx: int, flip_index: int, N: int) -> List[int]:\n",
    "    \"\"\"Return the indices of the bits that are flipped when going from s_idx to flip_index.\"\"\"\n",
    "    flipped_bits = s_idx ^ flip_index\n",
    "    flipped_indices = []\n",
    "    for k in range(N):\n",
    "        if (flipped_bits & (1 << k)) != 0:\n",
    "            flipped_indices.append(N - 1 - k)\n",
    "    return flipped_indices\n",
    "\n",
    "@njit\n",
    "def steady_state(A):\n",
    "    \"\"\"Calculates the steady state of a (left) stochastic matrix\"\"\"\n",
    "    # compute eigenvalues and corresponding eigenvectors for the transposed matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(A.T)\n",
    "    \n",
    "    # get the eigenvector corresponding to eigenvalue 1 (the steady state)\n",
    "    steady_state = np.abs(np.real(eigenvectors[:, np.argmax(np.real(eigenvalues))]))\n",
    "    \n",
    "    # normalize the vector to get a probability distribution\n",
    "    steady_state = steady_state / np.sum(steady_state)\n",
    "    \n",
    "    return steady_state.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d015206",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUXILARY SIMULATION FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "@njit\n",
    "def g_single(i: int, from_idx: int, to_idx: int, s: np.ndarray, w: np.ndarray, h: np.ndarray, J: np.ndarray):\n",
    "    \"\"\"Calculates the single flip probability.\"\"\"\n",
    "    sum_Js = np.sum(J[i, :] * s)\n",
    "    return np.exp(-w[from_idx, to_idx] - s[i] * (h[i] + sum_Js))\n",
    "\n",
    "@njit\n",
    "def g_double(i: int, j: int, from_idx: int, to_idx:int, s: np.ndarray, w: np.ndarray, h: np.ndarray, J: np.ndarray):\n",
    "    \"\"\"Calculates the double flip probability\"\"\"\n",
    "    sum_Js_i = np.sum(J[i, :] * s) - J[i, j] * s[j]\n",
    "    sum_Js_j = np.sum(J[j, :] * s) - J[i, j] * s[i]\n",
    "\n",
    "    return np.exp(-w[from_idx, to_idx] + J[i, j] * s[i] * s[j] - s[i] * (sum_Js_i + h[i]) - s[j] * (sum_Js_j + h[j]))\n",
    "\n",
    "@njit\n",
    "def choice(probabilities: np.ndarray) -> int:\n",
    "    \"\"\"A workaround for np.random.choice, which is unsupported by numba\"\"\"\n",
    "    cumulative_distribution = np.cumsum(probabilities)\n",
    "    return np.searchsorted(cumulative_distribution, np.random.random(), side =\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152fff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def compute_transition_matrix(w: np.ndarray, h: np.ndarray, J: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Computes the transition matrix for the given parameters.\"\"\"\n",
    "    N = len(h)  # number of spins in the lattice\n",
    "    transition_matrix = np.zeros((2**N, 2**N))\n",
    "\n",
    "    #sum over rows to fill\n",
    "    for from_idx in range(2**N):\n",
    "        s = index_to_spin_state(from_idx, N)\n",
    "        flip_probs = np.zeros((2**N))  # initialize with zeros\n",
    "\n",
    "        for i in range(N):\n",
    "            to_index = from_idx ^ (1 << i)\n",
    "            i_flipped = bits_flipped_indices(from_idx, to_index, N)[0]\n",
    "            flip_probs[to_index] = g_single(i_flipped, from_idx, to_index, s, w, h, J)  # single flip probabilities\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(i+1, N):\n",
    "                to_index = from_idx ^ (1 << i) ^ (1 << j)\n",
    "                i_flipped, j_flipped = bits_flipped_indices(from_idx, to_index, N)\n",
    "                flip_probs[to_index] = g_double(i_flipped, j_flipped, from_idx, to_index, s, w, h, J)  # double flip probabilities\n",
    "\n",
    "       # add the no-flip probability and store the flipping probabilities\n",
    "        no_flip_prob = 1 - sum(flip_probs)\n",
    "        flip_probs[from_idx] = no_flip_prob\n",
    "        transition_matrix[from_idx] = flip_probs\n",
    "\n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffbc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_w(w, h, J, step_size = 1e-4, no_flip_prob = 0):\n",
    "    \"\"\"Checks if w gives rise to a proper normalized W. Prints the minimal value of w required if it's not the case\"\"\"\n",
    "    min_scalar = 0\n",
    "    W = compute_transition_matrix(w, h, J)\n",
    "    self_probs = np.diag(W.copy())\n",
    "\n",
    "    if np.all(self_probs >= no_flip_prob):\n",
    "        return\n",
    "    else:\n",
    "        self_probs_old = self_probs.copy()\n",
    "        while True:\n",
    "            new_w      = w + np.ones(w.shape) * min_scalar\n",
    "            W          = compute_transition_matrix(new_w, h, J)\n",
    "            self_probs = np.diag(W)\n",
    "\n",
    "            # check if the self-transition probabilities are all at least no_flip_prob\n",
    "            if np.all(self_probs >= no_flip_prob):\n",
    "                break\n",
    "\n",
    "            # if the condition is not met, increase the scalar value and try again\n",
    "            min_scalar += step_size\n",
    "\n",
    "        assert np.all(self_probs_old >= no_flip_prob), f\"Need to use larger w matrix: \\n {new_w} \"\n",
    "\n",
    "def check_parameters(w, J, h):\n",
    "    \"\"\"Check if parameters are chosen to give rise to a normalized W that satisfies detailed balance\"\"\"\n",
    "    check_w(w, h, J)\n",
    "    assert np.allclose(J, J.T) and np.allclose(w, w.T) and np.all(J.diagonal() == 0),  \"Input matrices w and J should be symmetric and J should have a zero diagonal\"\n",
    "\n",
    "\n",
    "def check_detailed_balance(W):\n",
    "    \"\"\"\n",
    "    Check if the transition matrix W and stationary distribution pi satisfy the detailed balance condition.\n",
    "    \"\"\"\n",
    "    pi = steady_state(W)\n",
    "    n_states = W.shape[0]\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            assert np.isclose(W[i, j] * pi[i], W[j, i] * pi[j]), \"Transition matrix does not satisfy detailed balance\"\n",
    "\n",
    "\n",
    "def test_transition_matrix(W):\n",
    "    \"\"\"Test that the sum of the probabilities in each row of the transition matrix is 1 and there are no negative elements.\"\"\"\n",
    "    for row in W:\n",
    "        assert np.isclose(np.sum(row), 1), \"Row sums to \" + str(np.sum(row))\n",
    "        assert np.all(row >= 0), \"Negative probability in row \" + str(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c00f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  SIMULATION FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "@njit\n",
    "def spin_flip(s: np.ndarray, transition_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Flipping algorithm, uses precomputed transition matrix. \"\"\"\n",
    "    N = len(s)  # number of spins in the lattice\n",
    "\n",
    "    # calculate the index of the current state in the transition matrix\n",
    "    from_idx = spin_state_to_index(s)\n",
    "\n",
    "    # get probabilities from transition matrix\n",
    "    flip_probs = transition_matrix[from_idx]\n",
    "\n",
    "    # randomly choose a spin flip according to its probability of occurring\n",
    "    to_idx = choice(flip_probs)\n",
    "\n",
    "    # apply the chosen spin flip\n",
    "    flipped_indices = bits_flipped_indices(from_idx, to_idx, N)\n",
    "    \n",
    "    if len(flipped_indices)   == 0:  # no flip\n",
    "        pass\n",
    "    elif len(flipped_indices) == 1:  # single flip\n",
    "        i = flipped_indices[0]\n",
    "        s[i] *= -1\n",
    "    elif len(flipped_indices) == 2:  # double flip\n",
    "        i, j = flipped_indices\n",
    "        s[i] *= -1\n",
    "        s[j] *= -1\n",
    "    elif len(flipped_indices) == 3:  # triple flip\n",
    "        i, j, k = flipped_indices\n",
    "        s[i] *= -1\n",
    "        s[j] *= -1\n",
    "        s[k] *= -1\n",
    "    elif len(flipped_indices) == 4:  # quadruple flip\n",
    "        i, j, k, l = flipped_indices\n",
    "        s[i] *= -1\n",
    "        s[j] *= -1\n",
    "        s[k] *= -1\n",
    "        s[l] *= -1\n",
    "\n",
    "    return s\n",
    "\n",
    "@njit\n",
    "def simulate_dynamics(W: np.ndarray, steps: int, N: int, s = None) -> np.ndarray:\n",
    "    \"\"\"Simulates the dynamics of the system for the given number of steps.\"\"\"\n",
    "\n",
    "    if s is None:\n",
    "        s = np.ones(N, dtype=np.int64)\n",
    "    trajectory = np.empty((steps, N), dtype=np.int64)\n",
    "\n",
    "    for t in range(steps):\n",
    "        s = spin_flip(s, W)\n",
    "        trajectory[t] = s\n",
    "\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def infer_transition_matrix(trajectory: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Infers the transition matrix from a time series of the states of the system\"\"\"\n",
    "    N = trajectory.shape[1]  # number of spins in the lattice\n",
    "    steps = trajectory.shape[0]  # number of steps in the trajectory\n",
    "    transition_matrix = np.zeros((2**N, 2**N))\n",
    "\n",
    "    for t in range(steps - 1):\n",
    "        # convert the spin states to indices\n",
    "        s_idx = spin_state_to_index(trajectory[t])\n",
    "        next_s_idx = spin_state_to_index(trajectory[t + 1])\n",
    "\n",
    "        # increment the corresponding cell in the transition matrix\n",
    "        transition_matrix[s_idx, next_s_idx] += 1\n",
    "\n",
    "    # normalize each row to get probabilities\n",
    "    for i in range(2**N):\n",
    "        row_sum = np.sum(transition_matrix[i])\n",
    "        if row_sum > 0:  # avoid division by zero\n",
    "            transition_matrix[i] /= row_sum\n",
    "\n",
    "    return transition_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bb52bb6",
   "metadata": {},
   "source": [
    "## **Implementation of the Boltzmann Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  BOLTZMANN MACHINE AUXILARY FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "def all_possible_configs(N: int) -> np.ndarray:\n",
    "    '''Generates a 2^N by N matrix with all possible configurations of a binary spin system of size N'''\n",
    "    configs = np.zeros((2**N,N))\n",
    "    for i in range(2**N):\n",
    "        config = np.array([1 if x == '1' else -1 for x in np.binary_repr(i, width=N)])\n",
    "        configs[i] = config\n",
    "    return configs\n",
    "\n",
    "@njit\n",
    "def calcEnergy(config: np.ndarray, J: np.ndarray, h: np.ndarray) -> float:\n",
    "    '''Calculates the energy of a given configuration'''\n",
    "    config_float = config.astype(np.float64)  # convert config to float\n",
    "    energy = -np.dot(config_float.T, np.dot(J, config_float)) / 2 - np.dot(h, config_float)\n",
    "    return energy\n",
    "\n",
    "@njit\n",
    "def calcMag(config: np.ndarray) -> float:\n",
    "    ''' Magnetizations of a given configuration '''\n",
    "    return np.sum(config)\n",
    "\n",
    "@njit\n",
    "def calcCorr(config: np.ndarray) -> np.ndarray: \n",
    "    '''Calculates the spin-spin correlations of a given configuration. Returns a NxN matrix with the correlations'''\n",
    "    return np.outer(config, config.T)\n",
    "\n",
    "@njit\n",
    "def log_likelihood(p: np.ndarray, J: np.ndarray, h: np.ndarray, configs: np.ndarray) -> float:\n",
    "    \"\"\"Calculates the log-likelihood of the system under the Boltzmann distribution.\"\"\"\n",
    "    Z = 0\n",
    "    for config in configs:\n",
    "        Ene = calcEnergy(config, J, h)\n",
    "        Z += np.exp(-Ene)\n",
    "    logZ = np.log(Z)\n",
    "\n",
    "    log_likelihood = 0\n",
    "    for i, config in enumerate(configs):\n",
    "        Ene = calcEnergy(config, J, h)\n",
    "        log_likelihood += p[i] * (-Ene - logZ)\n",
    "\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  BOLTZMANN MACHINE FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "@njit\n",
    "def ising_solve_exact_simplified(N: int, J: np.ndarray, h: np.ndarray, configs: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:    \n",
    "    '''Calculates the free statistics for a single temperature using exact calculation'''\n",
    "    beta = 1.0\n",
    "    Z, C1, C2  = 0, np.zeros((N)), np.zeros((N,N))    #  initialize arrays to store variables                       \n",
    "                                           \n",
    "    for config in configs:\n",
    "        Ene  = calcEnergy(config,J,h)\n",
    "        Corr = calcCorr(config) \n",
    "        p    = np.exp(-beta * Ene)                    #  non-normalized probability of this  configuration at this temperature\n",
    "        Z  +=  p                                        \n",
    "        C1 +=  p * config                               \n",
    "        C2 +=  p * Corr\n",
    "\n",
    "    Ci   = C1 / Z\n",
    "    CiCj = C2 / Z\n",
    "        \n",
    "    return Ci,CiCj\n",
    "\n",
    "@njit\n",
    "def classical_boltzmann_machine(p: np.ndarray, N: int, configs: np.ndarray, maxiter: int, learning_rate: float, tol: float = 1e-14) -> Tuple[np.ndarray, np.ndarray, List[np.ndarray], List[np.ndarray], List[float]]:\n",
    "    '''Solves the inverse Ising problem. Returns weight matrices that generated the clamped statistics \n",
    "    and the inferred weight matrix'''\n",
    "    J_assym = 2.0 * np.random.random((N, N)) - 1.0   # random initial values between -1 and 1\n",
    "    J = (J_assym+ J_assym.T)/2                       # symmetrize the random matrix \n",
    "    np.fill_diagonal(J, 0)                           # set diagonal of J to 0 to ensure detailed balance\n",
    "    h = 2.0 * np.random.random(N) - 1.0              # random initial values between -1 and 1\n",
    "\n",
    "    J = J.astype(np.float64)\n",
    "    h = h.astype(np.float64)\n",
    "\n",
    "    # compute the expected spin values\n",
    "    Ci_clamp = np.dot(p, configs)\n",
    "\n",
    "    # compute the expected spin-spin correlations\n",
    "    CiCj_clamp = configs.T @ np.diag(p) @ configs\n",
    "        \n",
    "    #  initialize gradient ascent values  \n",
    "    it    = 0\n",
    "    delta_J = np.inf\n",
    "    delta_h = np.inf\n",
    "    # old_log_likelihood = -np.inf\n",
    "\n",
    "    # initialize lists to store the values of the parameters and the log-likelihood at each iteration\n",
    "    J_values = []\n",
    "    h_values = []\n",
    "    log_likelihood_values = []\n",
    "    \n",
    "    while (it < maxiter and (delta_J > tol or delta_h > tol)):    #  start gradient ascent\n",
    "        it += 1\n",
    "\n",
    "        #generate free statistics based on type of solver\n",
    "        Ci_free, CiCj_free = ising_solve_exact_simplified(N, J, h, configs) \n",
    "\n",
    "        # compute the updates for J and h\n",
    "        delta_J = learning_rate * (CiCj_clamp - CiCj_free)\n",
    "        delta_h = learning_rate * (Ci_clamp   - Ci_free)\n",
    "            \n",
    "        h     = h + delta_h               #  update weight matrix based on statistics  \n",
    "        J     = J + delta_J\n",
    "        \n",
    "        # compute the magnitude of the updates\n",
    "        delta_J = np.linalg.norm(delta_J)\n",
    "        delta_h = np.linalg.norm(delta_h)\n",
    "\n",
    "        # calculate the log-likelihood and check for convergence\n",
    "        new_log_likelihood = log_likelihood(p, J, h, configs)\n",
    "        # if np.abs(new_log_likelihood - old_log_likelihood) < tol:\n",
    "        #     break\n",
    "        # old_log_likelihood = new_log_elikelihood\n",
    "\n",
    "        # store the current values of the parameters and the log-likelihood\n",
    "        J_values.append(J)\n",
    "        h_values.append(h)\n",
    "        log_likelihood_values.append(new_log_likelihood)\n",
    "        \n",
    "    return J, h, J_values, h_values, log_likelihood_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40127f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  PLOTTING FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "def plot_scatter(ax, x, y, xlabel, ylabel, color, size=10):\n",
    "    '''Creates a scatter subplot'''\n",
    "    ax.scatter(x, y, s=size, marker='o', color=color)\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "def plot_convergence(J_values, h_values, log_likelihood_values, title='Convergence Plots', size=10):\n",
    "    '''Plots the convergence of the parameters and the log-likelihood.'''\n",
    "    it = len(J_values)\n",
    "    its = np.arange(1, it+1, 1)\n",
    "    its_diff = np.arange(1, it, 1)\n",
    "\n",
    "    J_diff = np.diff(J_values, axis=0)\n",
    "    h_diff = np.diff(h_values, axis=0)\n",
    "\n",
    "    J_max = np.linalg.norm(J_diff, axis=(1,2))\n",
    "    h_max = np.linalg.norm(h_diff, axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(25, 6));    #  make plots\n",
    "    fig.suptitle(title, fontsize=30, y = 1)\n",
    "    trans = mtransforms.ScaledTranslation(-20/72, 7/72, fig.dpi_scale_trans)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    plot_scatter(ax1, its_diff , J_max, \"Iterations\", r\"$ (\\Delta h)_{max}$\", \"IndianRed\", size)\n",
    "    ax1.text(0, 1.0, 'A.)', transform=ax1.transAxes + trans, fontsize='large',fontweight ='bold', va='bottom', fontfamily='sans-serif')\n",
    "    \n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    plot_scatter(ax2, its_diff , h_max, \"Iterations\", r\"$ (\\Delta J)_{max}$ \", \"SteelBlue\", size)\n",
    "    ax2.text(0, 1.0, 'B.)', transform=ax2.transAxes + trans, fontsize='large',fontweight ='bold', va='bottom', fontfamily='sans-serif')\n",
    "    \n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    ax3.scatter(its, log_likelihood_values, s=size, marker='o', color=\"Coral\")\n",
    "    ax3.set_xlabel(\"Iterations\", fontsize=20)\n",
    "    ax3.set_ylabel(\"Log Likelihood\", fontsize=20)\n",
    "    ax3.text(0, 1.0, 'C.)', transform=ax3.transAxes + trans, fontsize='large',fontweight ='bold', va='bottom', fontfamily='sans-serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_w(W: np.ndarray, J: np.ndarray, h: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Computes the parameters w from the flip probabilities, J, h, and the spin states.\"\"\"\n",
    "    # Initialize w with zeros\n",
    "    N = len(h)\n",
    "    w = np.zeros((2**N, 2**N), dtype = np.float64)\n",
    "\n",
    "    #sum over rows to fill\n",
    "    for from_idx in range(2**N):\n",
    "        s = index_to_spin_state(from_idx, N)\n",
    "        for to_idx in range(2**N):\n",
    "            # calculate w_ii\n",
    "            flipped_indices = bits_flipped_indices(from_idx, to_idx, N)\n",
    "            \n",
    "            if len(flipped_indices) == 0:  # no flip; self-transition\n",
    "                # w[from_idx, to_idx] = ???\n",
    "                pass\n",
    "\n",
    "            elif len(flipped_indices) == 1:  # single flip, compute wii\n",
    "                i = flipped_indices[0]\n",
    "                sum_Js = np.sum(J[i, :] * s)\n",
    "                w[from_idx, to_idx] = -np.log(W[from_idx,to_idx] + 1e-10) - s[i] * (h[i] + sum_Js)\n",
    "            elif len(flipped_indices) == 2:  # double flip, compute wij\n",
    "                j, i = flipped_indices\n",
    "                sum_Js_i = np.sum(J[i, :] * s) - J[i, j] * s[j]\n",
    "                sum_Js_j = np.sum(J[j, :] * s) - J[i, j] * s[i]\n",
    "                w[from_idx, to_idx] = -np.log(W[from_idx,to_idx]+ 1e-10) + J[i, j] * s[i] * s[j] - s[i] * (sum_Js_i + h[i]) - s[j] * (sum_Js_j + h[j])\n",
    "            \n",
    "            else: # triple or more flip\n",
    "                pass\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def infer_parameters(W: np.ndarray, maxiter: int = 2**20, learning_rate: float = 0.1, tolerance = 1e-10, plot = False) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Infers the parameters w, h, J from a given transition matrix.\"\"\"\n",
    "    N = int(np.log2(W.shape[0]))\n",
    "\n",
    "    # infer the equilibrium distribution p from W\n",
    "    p = steady_state(W)\n",
    "\n",
    "    # run the Boltzmann machine\n",
    "    configs = all_possible_configs(N)\n",
    "    J, h, J_values, h_values, log_likelihood_values = classical_boltzmann_machine(p, N, configs, maxiter, learning_rate, tolerance )\n",
    "\n",
    "    w = compute_w(W, J, h)\n",
    "\n",
    "    if plot == True:\n",
    "        plot_convergence(J_values, h_values, log_likelihood_values, title = 'BM Convergence')\n",
    "\n",
    "    return w, J, h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28df998d",
   "metadata": {},
   "source": [
    "## **Implementation of quantum Hamiltonian**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Pauli matrices globally\n",
    "PAULI_I = np.array([[1, 0], [0, 1]],    dtype=np.complex128)\n",
    "PAULI_X = np.array([[0, 1], [1, 0]],    dtype=np.complex128)\n",
    "PAULI_Y = np.array([[0, 1j], [-1j, 0]], dtype=np.complex128)\n",
    "PAULI_Z = np.array([[-1, 0], [0, 1]],   dtype=np.complex128)\n",
    "\n",
    "# create an array of Pauli matrices and their labels\n",
    "PAULI_MATRICES = np.array([PAULI_I, PAULI_X, PAULI_Y, PAULI_Z], dtype=np.complex128)\n",
    "PAULI_LABELS = ['I', 'X', 'Y', 'Z']\n",
    "\n",
    "def tensor_product(matrices: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"Compute the tensor product of a list of matrices.\"\"\"\n",
    "    result = matrices[0]\n",
    "    # iterate over each matrix in the list starting from the second one\n",
    "    for matrix in matrices[1:]:\n",
    "        result = kron(result, matrix)\n",
    "    return result\n",
    " \n",
    "def generate_interaction_matrices(num_qubits: int) -> Tuple[np.ndarray, np.ndarray, Dict[Tuple[str, ...], Optional[float]]]:\n",
    "    \"\"\"Constructs the tensor product of Pauli matrices for each qubit pair.\"\"\"\n",
    "    num_combinations = 4 ** num_qubits # total number of combinations of Pauli matrices for num_qubits\n",
    "    interaction_matrices = np.empty((num_combinations, 2 ** num_qubits, 2 ** num_qubits), dtype=np.complex128) \n",
    "    interaction_labels = np.empty((num_combinations, num_qubits), dtype=object)\n",
    "\n",
    "    # initialize an empty dictionary to store the weights associated with each interaction matrix\n",
    "    interaction_weights = {}\n",
    "\n",
    "    # enumerate over all possible combinations of Pauli matrices for num_qubits\n",
    "    for idx, matrix_indices in enumerate(product(range(4), repeat=num_qubits)):\n",
    "        # select the corresponding Pauli matrices for the current combination\n",
    "        matrices = PAULI_MATRICES[list(matrix_indices)]\n",
    "        # compute the tensor product of the selected matrices\n",
    "        interaction_matrix = tensor_product(matrices)\n",
    "\n",
    "        # store the computed tensor product matrix and its corresponding labe\n",
    "        interaction_matrices[idx] = interaction_matrix\n",
    "        label_tuple = tuple(PAULI_LABELS[i] for i in matrix_indices)\n",
    "        interaction_labels[idx] = label_tuple\n",
    "\n",
    "        # initialize the weight associated with this interaction matrix\n",
    "        # by default, it is set to None. You can change it later.\n",
    "        interaction_weights[label_tuple] = None\n",
    "\n",
    "    return interaction_matrices, interaction_labels, interaction_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a88de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_dict_to_array(interaction_labels: np.ndarray, interaction_weights: Dict[Tuple[str, ...], Optional[float]]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts the interaction_weights dictionary to a numpy array based on the order of interaction_labels.\n",
    "    \"\"\"\n",
    "    weights_array = np.array([interaction_weights[tuple(label)] if interaction_weights[tuple(label)] is not None else 0 for label in interaction_labels])\n",
    "    return weights_array\n",
    "\n",
    "def weights_array_to_dict(interaction_labels: np.ndarray, weights_array: np.ndarray) -> Dict[Tuple[str, ...], float]:\n",
    "    \"\"\"\n",
    "    Converts a numpy array to an interaction_weights dictionary based on the order of interaction_labels.\n",
    "    \"\"\"\n",
    "    interaction_weights = {tuple(label): weights_array[i] for i, label in enumerate(interaction_labels)}\n",
    "    return interaction_weights\n",
    "\n",
    "def generate_random_parameter_matrix(random_seed: int, num_qubits: int, interaction_labels: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a random parameter array for the random seed value random_seed.\n",
    "    Interactions containing more than 2-body interactions are set to zero.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)  # set the random seed value\n",
    "    num_params = 4**num_qubits   # calculate the number of parameters for the weight matrix\n",
    "    w_array = np.random.rand(num_params)  # generate a random parameter array of size num_params\n",
    "\n",
    "    # iterate over the interaction labels\n",
    "    for i, label_tuple in enumerate(interaction_labels):\n",
    "        # count the number of 'I' in the current label tuple\n",
    "        num_I = np.count_nonzero(label_tuple == 'I')\n",
    "        # if there are more than 2 'I', set the corresponding weight to 0\n",
    "        if num_I < num_qubits - 2:\n",
    "            w_array[i] = 0\n",
    "\n",
    "    w_array[0] = 0 # -log(Z) = 0\n",
    "    return w_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e605e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def hamiltonian_n_qubits(interaction_weights: np.ndarray, interaction_matrices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the Hamiltonian matrix of an n-qubit system\n",
    "    \"\"\"\n",
    "    num_qubits = int(np.log2(interaction_matrices.shape[1]))\n",
    "    H = np.zeros((2**num_qubits, 2**num_qubits), dtype=np.complex128)\n",
    "    for i in range(len(interaction_weights)):\n",
    "        H -= interaction_weights[i] * interaction_matrices[i]\n",
    "\n",
    "    return H"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "237de384",
   "metadata": {},
   "source": [
    "## **Implementation of density matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54396d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def expmat(A: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the exponential of a given matrix `A'.\n",
    "    \"\"\"\n",
    "    A = 0.5 * (A + np.transpose(np.conjugate(A)))\n",
    "    evals, evecs = np.linalg.eigh(A)\n",
    "    N = len(evals)\n",
    "    res = np.zeros((N,N),np.complex128)\n",
    "    for i in range(N):\n",
    "        eigenvector = evecs[:,i]\n",
    "        projector = np.outer(eigenvector,eigenvector.conj())\n",
    "        res += np.exp(evals[i]) * projector\n",
    "    return res\n",
    "\n",
    "@njit\n",
    "def logmat(A: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the natural logarithm of a given matrix `A`. Same structure as expmat.\n",
    "    \"\"\"\n",
    "    A = 0.5 * (A + np.transpose(np.conjugate(A)))\n",
    "    evals, evecs = np.linalg.eigh(A)\n",
    "    N = len(evals)\n",
    "    res = np.zeros((N,N),np.complex128)\n",
    "    for i in range(N):\n",
    "        eigenvector = evecs[:,i]\n",
    "        projector = np.outer(eigenvector,eigenvector.conj())\n",
    "        res += np.log(evals[i]) * projector\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389015e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def rho_model(interaction_weights: np.ndarray, interaction_matrices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the density matrix of an n-qubit system using the Hamiltonian\n",
    "    and the interaction matrices, and then normalizes it. Exact Diagonalization.\n",
    "    \"\"\"\n",
    "    H = hamiltonian_n_qubits(interaction_weights, interaction_matrices)  # get Hamiltonian matrix\n",
    "    rho = expmat(-H)                                                     # definition of rho\n",
    "\n",
    "    Z = np.real(np.trace(rho))                                           # get Z\n",
    "    rho /= Z                                                             # normalize such that Tr[rho] = 1\n",
    "    # for errors in numerical precision\n",
    "    rho += 1e-6 * np.eye(rho.shape[0])\n",
    "\n",
    "    return rho \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29064da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_density_matrix(rho, check_negative = False):  \n",
    "    \"\"\"Checks if the trace of rho is equal to 1 and if its eigenvalues are positive-semidefinite. Optional check for negative rho entries\"\"\"\n",
    "\n",
    "    eigenvalues, _ = np.linalg.eig(rho)\n",
    "    # check if rho is positive semi-definite\n",
    "    if not np.all(eigenvalues >= 1e-6):\n",
    "        raise ValueError(f\"Matrix rho is not positive semi-definite. rho:\\n{np.linalg.eigh(rho)[0]} \\n {rho}\")\n",
    "    \n",
    "    # check if rho is Hermitian\n",
    "    if not np.allclose(rho, rho.conj().T):\n",
    "        raise ValueError(f\"Matrix rho is not Hermitian. rho: \\n{rho}\")\n",
    "    \n",
    "    # check if trace of rho is equal to 1\n",
    "    if not np.isclose(np.trace(rho), 1):\n",
    "        raise ValueError(f\"The trace of rho is not equal to 1. rho: {np.trace(rho)} \\n {rho}\")\n",
    "    \n",
    "    if check_negative:\n",
    "        # check if rho has negative elements\n",
    "        if not np.all(rho >= 0):\n",
    "            raise ValueError(f\"Matrix rho contains negative values: \\n{rho}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eceb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_odd_y_interactions_to_zero(interaction_labels, interaction_weights):\n",
    "    # iterate over each label tuple\n",
    "    for label_array in interaction_labels:\n",
    "        # convert numpy array to tuple\n",
    "        label_tuple = tuple(label_array)\n",
    "        # count the number of 'Y' in the label tuple\n",
    "        num_y = label_tuple.count('Y')\n",
    "\n",
    "        # if the count is odd, set the corresponding weight to 0\n",
    "        if num_y % 2 == 1:\n",
    "            interaction_weights[label_tuple] = 0\n",
    "\n",
    "    return interaction_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a465e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_qm_parameters(interaction_matrices, interaction_labels, interaction_weights):\n",
    "    for label_array in interaction_labels:\n",
    "        # convert numpy array to tuple\n",
    "        label_tuple = tuple(label_array)\n",
    "        # count the number of 'Y' in the label tuple\n",
    "        num_y = label_tuple.count('Y')\n",
    "\n",
    "        # if the count is odd, check the weight\n",
    "        if num_y % 2 == 1:\n",
    "            assert interaction_weights[label_tuple] == 0 or interaction_weights[label_tuple] == None, f'Odd Y-interactions have non-zero components: {label_tuple} {interaction_weights[label_tuple]} '\n",
    "        \n",
    "        # check if all z-terms are smaller than |1|\n",
    "        if 'Z' in label_tuple:\n",
    "            if interaction_weights[label_tuple] != None:\n",
    "                assert abs(interaction_weights[label_tuple]) < 1, f'Z interactions larger than |1|: {label_tuple} {interaction_weights[label_tuple]}'\n",
    "        \n",
    "        #check first two rules using negativity. Possible to implement this better, but this will do\n",
    "        interaction_weights_array = weights_dict_to_array(interaction_labels, interaction_weights)\n",
    "        rho = rho_model(interaction_weights_array, interaction_matrices)\n",
    "        check_density_matrix(rho, check_negative = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a83f3af",
   "metadata": {},
   "source": [
    "## **Implementation of the Quantum Boltzmann Machine**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a28eba30",
   "metadata": {},
   "source": [
    "Now that we can properly generate the interaction matrices, associate a weight with them and obtain the density matrix. We can build the quantum boltzmann machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40393e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###QBM AUXILLARY FUNCTIONS\n",
    "#----------------------------------------------------------------------------------------------\n",
    "@njit\n",
    "def observables(rho: np.ndarray, interaction_matrices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the expectation values of the interaction matrices [observables]\n",
    "    \"\"\"\n",
    "    obs = np.zeros(len(interaction_matrices), dtype=np.complex128)\n",
    "    rho_contig = np.ascontiguousarray(rho)\n",
    "\n",
    "    for i, interaction_matrix in enumerate(interaction_matrices):   \n",
    "        interaction_matrix_contig = np.ascontiguousarray(interaction_matrix)\n",
    "        obs[i] = np.real(np.trace(np.dot(rho_contig, interaction_matrix_contig)))\n",
    "    return obs\n",
    "\n",
    "@njit\n",
    "def KL_divergence(eta: np.ndarray, rho: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the KL divergence between the model and target distribution.\n",
    "    \"\"\"\n",
    "    return np.real(np.trace(eta@(logmat(eta)-logmat(rho))))\n",
    "\n",
    "@njit\n",
    "def QM_likelihood(eta: np.ndarray, rho: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the quantum Likelihood of the distribution\n",
    "    \"\"\"\n",
    "    return -np.real(np.trace(eta @ logmat(rho)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58b82f56",
   "metadata": {},
   "source": [
    "Now build the actual QBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def quantum_boltzmann_machine(\n",
    "    interaction_matrices: np.ndarray, \n",
    "    learning_rate: float, \n",
    "    maxiter: int, \n",
    "    tolerance: float, \n",
    "    w_initial: np.ndarray, \n",
    "    eta: np.ndarray = np.array([math.nan]), \n",
    "    w_eta: np.ndarray = np.array([math.nan])\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, int]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Train the Quantum Boltzmann Machine (QBM) to fit the target distribution eta.    \n",
    "    \"\"\"\n",
    "    # compute target density matrix using ED if oracle w_eta is provided, otherwise use provided eta\n",
    "    if np.isnan(eta).any():\n",
    "        assert not np.isnan(w_eta).any(), \"Either eta or w_eta must be provided\"\n",
    "        eta = rho_model(w_eta, interaction_matrices)\n",
    "\n",
    "    obs_clamped = observables(eta, interaction_matrices)  # get clamped QM statistics\n",
    "\n",
    "    w = w_initial.copy()  # get initial weights for free QM statistics\n",
    "    rho = rho_model(w, interaction_matrices)  # generate the density matrix rho for the initial weights\n",
    "    obs_model = observables(rho, interaction_matrices)  # get free QM statistics\n",
    "\n",
    "    it = 0  # initialize gradient ascent loop\n",
    "    diff = np.inf\n",
    "    W_list, lk_list, kl_list = np.zeros(maxiter), np.zeros(maxiter), np.zeros(maxiter)  # initialize values to store\n",
    "\n",
    "    consecutive_small_change = 0  # counter for consecutive iterations with small change in W_max\n",
    "    prev_W_diff = 0.0  # previous value of W_max\n",
    "\n",
    "    while diff > tolerance and it < maxiter and consecutive_small_change < 20:\n",
    "        rho = rho_model(w, interaction_matrices)  # get free QM statistics\n",
    "        obs_model = observables(rho, interaction_matrices)\n",
    "        w_previous = w.copy()\n",
    "        w += learning_rate * np.real(obs_clamped - obs_model)  # Update weights\n",
    "\n",
    "        if np.isnan(w_eta).any():\n",
    "            W_diff = np.max(np.abs(w - w_previous))\n",
    "            W_list[it] = W_diff\n",
    "\n",
    "        else:\n",
    "            Wmax = np.max(np.abs(w-w_eta))\n",
    "            W_list[it] = Wmax                  \n",
    "\n",
    "        # check if W_max has a small change compared to the previous iteration\n",
    "        if np.abs(W_diff - prev_W_diff) < 1e-14:\n",
    "            consecutive_small_change += 1\n",
    "        else:\n",
    "            consecutive_small_change = 0  # reset counter if W_max changes significantly\n",
    "        prev_W_diff = W_diff\n",
    "\n",
    "        diff = np.max(np.abs(obs_model - obs_clamped))  # evaluate differences in clamped and model statistics\n",
    "\n",
    "        lk_list[it] = QM_likelihood(eta, rho)\n",
    "        kl_list[it] = KL_divergence(eta, rho)\n",
    "        it += 1\n",
    "    \n",
    "    return w, lk_list, kl_list, W_list, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  PLOTTING FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "def plot(it, Wmax, kl, lk, title='Convergence Plots', size=10):\n",
    "    fig = plt.figure(figsize=(16, 6));                           #  make plots\n",
    "    fig.suptitle(title, fontsize=30, y = 1)\n",
    "    trans = mtransforms.ScaledTranslation(-20/72, 7/72, fig.dpi_scale_trans)\n",
    "    its= np.arange(1,it+1,1)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.scatter(its, Wmax[:it], s=size, marker='o', color=\"SlateBlue\")\n",
    "    ax1.set_xlabel(\"Iterations\", fontsize=20)\n",
    "    ax1.set_ylabel(r\"$ (\\Delta w)_{max}$\", fontsize=20)\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.text(0, 1.0, 'A.)', transform=ax1.transAxes + trans, fontsize='large',fontweight ='bold', va='bottom', fontfamily='sans-serif')\n",
    "   \n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.scatter(its, kl[:it], s=size, marker='o', color=\"ForestGreen\")\n",
    "    ax2.set_xlabel(\"Iterations\", fontsize=20)\n",
    "    ax2.set_ylabel(\"KL Divergence\", fontsize=20)\n",
    "    ax2.set_yscale('symlog')  #symlog for when the KL divergence goes to zero\n",
    "    ax2.text(0, 1.0, 'B.)', transform=ax2.transAxes + trans, fontsize='large',fontweight ='bold', va='bottom', fontfamily='sans-serif')\n",
    "\n",
    "    # ax3 = fig.add_subplot(1, 3, 3)\n",
    "    # ax3.scatter(its, lk[:it], s=size, marker='o', color=\"Coral\")\n",
    "    # ax3.set_xlabel(\"Iterations\", fontsize=20)\n",
    "    # ax3.set_ylabel(\"Log Likelihood\", fontsize=20)\n",
    "    # ax3.set_yscale('log')\n",
    "    # # ax3.set_ylim([0.482015, 0.482030])\n",
    "    # ax3.text(0, 1.0, 'B.)', transform=ax3.transAxes + trans, fontsize='large',fontweight ='bold', va='bottom', fontfamily='sans-serif')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "514281ad",
   "metadata": {},
   "source": [
    "## **Bidirectional Conversion of Density Matrices and Transition Matrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45b0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def transition_matrix_to_density_matrix(W: np.ndarray) -> np.ndarray:\n",
    "    # calculate steady-state distribution p\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(W.T) #switch row to collumn normalized by transposing\n",
    "\n",
    "    p = np.abs(eigenvectors[:, np.argmax(np.real(eigenvalues))])\n",
    "    p = p / np.sum(p) #normalize \n",
    "\n",
    "    # calculate the matrix A\n",
    "    sqrt_p_diag     = np.diag(np.sqrt(p))\n",
    "    inv_sqrt_p_diag = np.diag(1 / np.sqrt(p))\n",
    "    \n",
    "    A = inv_sqrt_p_diag @ W.T @ sqrt_p_diag\n",
    "\n",
    "    # symmetrize A to make it Hermitian\n",
    "    A = 0.5 * (A + np.transpose(np.conjugate(A)))\n",
    "\n",
    "    # add a scalar constant to all eigenvalues to make them non-negative (ensuring rho is positive semidefinite)\n",
    "    min_eigval = np.min(np.real(np.linalg.eigvals(A)))\n",
    "    if min_eigval < 0:\n",
    "        A += (np.abs(min_eigval) + 1e-4) * np.eye(A.shape[0])\n",
    "\n",
    "    #  normalize such that Tr[rho] = 1\n",
    "    rho = A / np.real(np.trace(A))    \n",
    "    rho = rho.astype(np.complex128) #make it complex    \n",
    "\n",
    "    return rho\n",
    "\n",
    "@njit\n",
    "def density_matrix_to_transition_matrix(rho: np.ndarray) -> np.ndarray:\n",
    "    # obtain the steady-state distribution √p\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(rho)\n",
    "    sqrt_p = np.abs(eigenvectors[:, np.argmax(np.real(eigenvalues))])\n",
    "\n",
    "    # square the elements of the eigenvector and normalize to obtain the steady-state distribution\n",
    "    p = sqrt_p**2\n",
    "    p = p / np.sum(p)  # normalize\n",
    "    epsilon = 1e-10  # small constant to prevent division by zero\n",
    "    p = p + epsilon\n",
    "\n",
    "    sqrt_p_diag     = np.diag(np.sqrt(p))\n",
    "    inv_sqrt_p_diag = np.diag(1 / np.sqrt(p))\n",
    "\n",
    "    # calculate the matrix A\n",
    "    A = np.real(rho)\n",
    "\n",
    "    # compute the transition matrix W \n",
    "    W = sqrt_p_diag @ A @ inv_sqrt_p_diag\n",
    "    W = W.T #switch back to row normalized by transposing\n",
    "\n",
    "    # normalize each row to ensure the sum of each row equals 1\n",
    "    W_row_sum = W.sum(axis=1)\n",
    "    for i in range(W.shape[0]):\n",
    "        W[i, :] /= W_row_sum[i]\n",
    "\n",
    "    return W\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e3c3306",
   "metadata": {},
   "source": [
    "## **Quantum-Classical Mapping**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41ea891f",
   "metadata": {},
   "source": [
    "### Building the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92601ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_mapping(w: np.ndarray, J: np.ndarray, h: np.ndarray, learning_rate_qbm: float, maxiter_qbm: int, plot_convergence = False, perform_checks = True) -> np.ndarray:\n",
    "    N = len(h)\n",
    "\n",
    "    #get the transition matrix\n",
    "    W = compute_transition_matrix(w,h,J)\n",
    "\n",
    "    #convert it to a target density matrix\n",
    "    eta = transition_matrix_to_density_matrix(W)\n",
    "\n",
    "    # test if W and eta are valid\n",
    "    if perform_checks:\n",
    "        test_transition_matrix(W)\n",
    "        check_density_matrix(eta)\n",
    "        \n",
    "    # learning parameters qbm\n",
    "    tolerance = 1e-14\n",
    "    random_seed = 444\n",
    "\n",
    "    # set initial weights for QBM\n",
    "    interaction_matrices, interaction_labels, _ = generate_interaction_matrices(N)\n",
    "    w_initial= generate_random_parameter_matrix(random_seed + 1, N, interaction_labels)\n",
    "\n",
    "    #infer its parameters using the QBM\n",
    "    w_qm, lk, kl, Wdiff, it = quantum_boltzmann_machine(interaction_matrices, learning_rate_qbm, maxiter_qbm, tolerance, w_initial, eta=eta)\n",
    "    \n",
    "    #plot its convergence if needed\n",
    "    if plot_convergence:\n",
    "        plot(it, Wdiff, kl, lk, title='QBM Convergence', size=10)\n",
    "\n",
    "    return w_qm\n",
    "\n",
    "\n",
    "def inverse_mapping(w_qm: np.ndarray, learning_rate_bm: float, maxiter_bm: int, plot_convergence = False, perform_checks = True) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    N = int(np.log(w_qm.shape[0]) / np.log(4))\n",
    "\n",
    "    #qm hamiltonian to density matrix\n",
    "    interaction_matrices, _, _ = generate_interaction_matrices(N)\n",
    "    rho = rho_model(w_qm, interaction_matrices)\n",
    "\n",
    "    #density matrix to transition matrix\n",
    "    W = density_matrix_to_transition_matrix(rho)\n",
    "\n",
    "    # test if rho and W are valid\n",
    "    if perform_checks:\n",
    "        check_density_matrix(rho)\n",
    "        test_transition_matrix(W)\n",
    "\n",
    "    #infer the classical parameters using a classical boltzmann machine\n",
    "    w, J, h = infer_parameters(W, maxiter_bm, learning_rate_bm, plot = plot_convergence)\n",
    "    \n",
    "    return W, w, J, h\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37a20f6f",
   "metadata": {},
   "source": [
    "### Analyzing the mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bece4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  ANALYZING HELPER FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "def qm_interaction_label_to_string(interaction_label: Tuple[str, ...]) -> str:\n",
    "    \"\"\"Convert an quantum interaction label tuple to a string (h, J or sigma)\"\"\"\n",
    "    # Find indices of all non-I terms\n",
    "    non_i_indices = [i for i, val in enumerate(interaction_label) if val != 'I']\n",
    "    # Generate string based on number of non-I terms\n",
    "    if len(non_i_indices) == 0:\n",
    "        return f\"$\\log(Z)$\"\n",
    "    elif len(non_i_indices) == 1:\n",
    "        return f\"$h_{{{non_i_indices[0]+1}}}^{{{interaction_label[non_i_indices[0]]}}}$\"\n",
    "    elif len(non_i_indices) == 2:\n",
    "        return f\"$J_{{{non_i_indices[0]+1}{non_i_indices[1]+1}}}^{{{interaction_label[non_i_indices[0]]}{interaction_label[non_i_indices[1]]}}}$\"\n",
    "    else:\n",
    "        i_terms = \"\".join([str(idx+1) for idx in non_i_indices])\n",
    "        k_terms = \"\".join([interaction_label[idx] for idx in non_i_indices])\n",
    "        return f\"$\\\\sigma_{{{i_terms}}}^{{{k_terms}}}$\"\n",
    "\n",
    "def qm_string_to_interaction_label(label_string: str, N: int) -> Tuple[str, ...]:\n",
    "    \"\"\"Convert a quantum string label to an interaction label tuple.\"\"\"\n",
    "    # check if the string starts with 'l' (log Z)\n",
    "    if label_string.startswith('l'):\n",
    "        return tuple('I' for _ in range(N))\n",
    "\n",
    "    # initialize a list of 'I's of length N\n",
    "    interaction_label = ['I'] * N\n",
    "\n",
    "    if label_string.startswith('$\\l'):\n",
    "        return tuple(interaction_label)\n",
    "\n",
    "    # check if the string starts with 'h' (bias)\n",
    "    if label_string.startswith('$h'):\n",
    "        # use regex to find the indices and axis in the label string\n",
    "        m = re.match(r\"\\$h_\\{(\\d+)\\}\\^\\{(\\w)\\}\\$\", label_string)\n",
    "        index = int(m.group(1))\n",
    "        axis = m.group(2)\n",
    "\n",
    "        # replace the corresponding 'I' with axis\n",
    "        interaction_label[index - 1] = axis\n",
    "\n",
    "    # check if the string starts with 'J' (two-spin interaction)\n",
    "    elif label_string.startswith('$J'):\n",
    "        m = re.match(r\"\\$J_\\{(\\d+)(\\d+)\\}\\^\\{(\\w)(\\w)\\}\\$\", label_string)\n",
    "        indices = (int(m.group(1)), int(m.group(2)))\n",
    "        axes = (m.group(3), m.group(4))\n",
    "\n",
    "        # replace the corresponding 'I's with axes\n",
    "        for i in range(2):\n",
    "            interaction_label[indices[i] - 1] = axes[i]\n",
    "\n",
    "    # otherwise, assume the string starts with '\\sigma' (multi-spin interaction)\n",
    "    else:\n",
    "        m = re.match(r\"\\$\\\\sigma_\\{(.+)\\}\\^\\{(.+)\\}\\$\", label_string)\n",
    "        indices = tuple(map(int, m.group(1)))\n",
    "        axes = tuple(m.group(2))\n",
    "\n",
    "        # replace the corresponding 'I's with axes\n",
    "        for i in range(len(indices)):\n",
    "            interaction_label[indices[i] - 1] = axes[i]\n",
    "\n",
    "    return tuple(interaction_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c498e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_forward_parameter_mapping(start: float, end: float, steps: int, param: str, index: Tuple[int], w: np.ndarray, J: np.ndarray, h: np.ndarray, learning_rate_qbm: float, maxiter_qbm: int):\n",
    "    \"\"\"Plot change of QM parameters when a single classical parameter is varied.\"\"\"\n",
    "    # check that the input matrices are symmetric and J has a zero diagonal\n",
    "    check_parameters(w, J, h)\n",
    "\n",
    "    # create array of parameter values to test\n",
    "    qm_param_values = np.linspace(start, end, steps)\n",
    "\n",
    "    # create lists to hold quantum parameter values\n",
    "    quantum_params = []\n",
    "\n",
    "    N = len(h)\n",
    "\n",
    "    for idx, value in enumerate(qm_param_values):\n",
    "        # update the corresponding parameter\n",
    "        if param == 'w':\n",
    "            w[index] = value\n",
    "            w[index[::-1]] = value    # update symmetric element\n",
    "        elif param == 'J':\n",
    "            J[index] = value\n",
    "            J[index[::-1]] = value    # update symmetric element\n",
    "        elif param == 'h':\n",
    "            h[index[0]] = value\n",
    "\n",
    "        # check if new parameters are valid\n",
    "        check_parameters(w, J, h)\n",
    "        \n",
    "        # forward mapping [only plot the last iteration]\n",
    "        w_qm = forward_mapping(w, J, h, learning_rate_qbm, maxiter_qbm, plot_convergence = False)\n",
    "\n",
    "        # add to list of quantum parameters\n",
    "        quantum_params.append(w_qm)\n",
    "\n",
    "    return quantum_params\n",
    "\n",
    "def analyze_inverse_parameter_mapping(start: float, end: float, steps: int, quantum_param_label: str, w_qm: np.ndarray, learning_rate_bm: float, maxiter_bm: int, classical_params_to_plot = None, threshold=0.01):\n",
    "    \"\"\"Plot change of Classical parameters when a single Quantum parameter is varied.\"\"\"\n",
    "    N  = int(np.log(w_qm.shape[0]) / np.log(4))\n",
    "    \n",
    "    # create array of quantum parameter values to test\n",
    "    quantum_param_values = np.linspace(start, end, steps)\n",
    "\n",
    "    # create lists to hold classical parameter values\n",
    "    w_vals = []\n",
    "    J_vals = []\n",
    "    h_vals = []\n",
    "\n",
    "    # find the index of quantum_param_label in interaction_labels\n",
    "    _, _, interaction_weights = generate_interaction_matrices(N)\n",
    "    param_index = list(interaction_weights.keys()).index((quantum_param_label))     \n",
    "\n",
    "    for idx, value in enumerate(quantum_param_values):\n",
    "        # update the quantum parameter\n",
    "        w_qm[param_index] = value\n",
    "\n",
    "        # perform the inverse mapping [only plot the last iteration]\n",
    "        w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False)\n",
    "\n",
    "        # add to lists\n",
    "        w_vals.append(w)\n",
    "        J_vals.append(J)\n",
    "        h_vals.append(h)\n",
    "\n",
    "    return w_vals, J_vals, h_vals\n",
    "\n",
    "def check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm):\n",
    "    \"\"\"\n",
    "    Perform a parameter sweep and plot the absolute inversion error if too large.\n",
    "    \"\"\"\n",
    "    qm_param_values = np.linspace(start, end, steps)\n",
    "    inversion_error = []\n",
    "\n",
    "    for idx, value in enumerate(qm_param_values):\n",
    "        if param == 'w':\n",
    "            w[index] = value\n",
    "            w[index[::-1]] = value\n",
    "        elif param == 'J':\n",
    "            J[index] = value\n",
    "            J[index[::-1]] = value\n",
    "        elif param == 'h':\n",
    "            h[index[0]] = value\n",
    "\n",
    "        check_parameters(w, J, h)\n",
    "\n",
    "        w_qm = forward_mapping(w, J, h, learning_rate_qbm, maxiter_qbm, plot_convergence=False, perform_checks=False)\n",
    "        W_recovered, w_recovered, J_recovered, h_recovered = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence=False, perform_checks=False)\n",
    "        \n",
    "        error = np.sum(np.abs(w - w_recovered)) + np.sum(np.abs(J - J_recovered)) + np.sum(np.abs(h - h_recovered))\n",
    "        inversion_error.append(error)\n",
    "\n",
    "    if any(np.array(inversion_error) > 1e-3):\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(qm_param_values, inversion_error)\n",
    "        classical_param_index_str = \"\".join(str(idx + 1) for idx in index)\n",
    "        plt.title(f'Absolute Inversion error when varying ${param}_{{ {classical_param_index_str} }}$')\n",
    "        plt.xlabel(f'${param}_{{ {classical_param_index_str} }}$')\n",
    "        plt.ylabel('Sum of absolute error between initial and recovered parameters')\n",
    "        plt.show()\n",
    "        assert False, 'Inversion error too large!'\n",
    "\n",
    "\n",
    "def check_inversion_error_inverse(start, end, steps, quantum_param_label, w_qm, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm):\n",
    "    \"\"\"\n",
    "    Perform a parameter sweep and plot the absolute inversion error if too large.\n",
    "    \"\"\"\n",
    "    N  = int(np.log(w_qm.shape[0]) / np.log(4))\n",
    "\n",
    "    qm_param_values = np.linspace(start, end, steps)\n",
    "    inversion_error = []\n",
    "    interaction_matrices, interaction_labels, interaction_weights = generate_interaction_matrices(N)\n",
    "    \n",
    "    # find the index of quantum_param_label in interaction_labels\n",
    "    _, _, interaction_weights = generate_interaction_matrices(N)\n",
    "    param_index = list(interaction_weights.keys()).index((quantum_param_label))     \n",
    "\n",
    "\n",
    "    for value in qm_param_values:\n",
    "        w_qm[param_index] = value\n",
    "\n",
    "        check_qm_parameters(interaction_matrices,interaction_labels,interaction_weights)\n",
    "\n",
    "        W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence=False, perform_checks=False)\n",
    "        w_qm_recovered = forward_mapping(w, J, h, learning_rate_qbm, maxiter_qbm, plot_convergence=False, perform_checks=False)\n",
    "        \n",
    "        error = np.sum(np.abs(w_qm - w_qm_recovered))\n",
    "        inversion_error.append(error)\n",
    "\n",
    "    if any(np.array(inversion_error) > 1e-3):\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(qm_param_values, inversion_error)\n",
    "        label = qm_interaction_label_to_string(quantum_param_label)\n",
    "\n",
    "        plt.title(f'Absolute Inversion error when varying {label} $')\n",
    "        plt.xlabel(label)\n",
    "        plt.ylabel('Error')\n",
    "        plt.ylabel('Sum of absolute error between initial and recovered parameters')\n",
    "        plt.show()\n",
    "        assert False, 'Inversion error too large!'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7555b516",
   "metadata": {},
   "source": [
    "### Plotting the mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6da1cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  PLOTTING HELPER FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "def color_dictionary(N):\n",
    "    # dictionary to map string labels to color\n",
    "    label_color_map = {}\n",
    "\n",
    "    #sort them alphabetically and numerically\n",
    "    _, interaction_labels, _ = generate_interaction_matrices(N)\n",
    "\n",
    "    qm_str_labels = [qm_interaction_label_to_string(label) for label in interaction_labels]\n",
    "    sorted_qm_str_labels = sorted(qm_str_labels, key=lambda x: (x[0].isalpha(), x))\n",
    "\n",
    "    green_tot, blue_tot, purple_tot, green_count, blue_count, purple_count = 0,0,0,0,0,0\n",
    "\n",
    "    #count how often a label appears\n",
    "    for i, qm_str_label in enumerate(sorted_qm_str_labels):\n",
    "        if qm_str_label.startswith('$h'):\n",
    "            if 'X' in qm_str_label:\n",
    "                green_tot += 1\n",
    "            elif 'Y' in qm_str_label:\n",
    "                blue_tot += 1\n",
    "            elif 'Z' in qm_str_label:\n",
    "                purple_tot += 1\n",
    "\n",
    "    for i, qm_str_label in enumerate(sorted_qm_str_labels):\n",
    "    # check if the string starts with 'h' (bias)\n",
    "        if qm_str_label.startswith('$h'):\n",
    "            if 'X' in qm_str_label:\n",
    "                green_count += 1\n",
    "                label_color_map[qm_str_label] = plt.cm.Greens(0.4 + 0.2 * green_count / green_tot)\n",
    "            elif 'Y' in qm_str_label:\n",
    "                blue_count += 1\n",
    "                label_color_map[qm_str_label] = plt.cm.Blues(0.4 + 0.2 * blue_count / blue_tot)\n",
    "            elif 'Z' in qm_str_label:\n",
    "                purple_count += 1\n",
    "                label_color_map[qm_str_label] = plt.cm.Purples(0.4 + 0.2 * purple_count / purple_tot)\n",
    "\n",
    "        # check if the string starts with 'J' (two-spin interaction)\n",
    "        elif qm_str_label.startswith('$J'):\n",
    "            if 'X' in qm_str_label and 'Y' in qm_str_label:\n",
    "                label_color_map[qm_str_label] = 'MediumSlateBlue'\n",
    "            elif 'X' in qm_str_label and 'Z' in qm_str_label:\n",
    "                label_color_map[qm_str_label] = 'Orchid'\n",
    "            elif 'Y' in qm_str_label and 'Z' in qm_str_label:\n",
    "                label_color_map[qm_str_label] = 'Cornflowerblue'\n",
    "            elif 'XX' in qm_str_label:\n",
    "                label_color_map[qm_str_label] = 'IndianRed'\n",
    "            elif 'YY' in qm_str_label:\n",
    "                label_color_map[qm_str_label] = 'Khaki'\n",
    "            elif 'ZZ' in qm_str_label:\n",
    "                label_color_map[qm_str_label] = 'LightSalmon'\n",
    "\n",
    "        # otherwise, assume the string starts with '\\sigma' (multi-spin interaction)\n",
    "        else:\n",
    "            label_color_map[qm_str_label] = 'HotPink'\n",
    "\n",
    "    return label_color_map\n",
    "\n",
    "def line_type_dictionary(N):\n",
    "    # dictionary to map string labels to color\n",
    "    label_line_map = {}\n",
    "\n",
    "    #sort them alphabetically and numerically\n",
    "    _, interaction_labels, _ = generate_interaction_matrices(N)\n",
    "\n",
    "    qm_str_labels = [qm_interaction_label_to_string(label) for label in interaction_labels]\n",
    "    sorted_qm_str_labels = sorted(qm_str_labels, key=lambda x: (x[0].isalpha(), x))\n",
    "\n",
    "    for qm_str_label in sorted_qm_str_labels:\n",
    "        # check if the string starts with 'h' (bias)\n",
    "        if qm_str_label.startswith('$h'):\n",
    "            if '1' in qm_str_label:\n",
    "                label_line_map[qm_str_label] = '-'\n",
    "            if '2' in qm_str_label:\n",
    "                label_line_map[qm_str_label] = '--'\n",
    "            if '3' in qm_str_label:\n",
    "                label_line_map[qm_str_label] = ':'\n",
    "            if '4' in qm_str_label:\n",
    "                label_line_map[qm_str_label] = '-.'\n",
    "\n",
    "        # check if the string starts with 'J' (two-spin interaction)\n",
    "        # elif qm_str_label.startswith('$J'):\n",
    "        #     if '1' in qm_str_label:\n",
    "        #         label_line_map[qm_str_label] = '-'\n",
    "        #     if '2' in qm_str_label:\n",
    "        #         label_line_map[qm_str_label] = '--'\n",
    "        #     if '3' in qm_str_label:\n",
    "        #         label_line_map[qm_str_label] = ':'\n",
    "        #     if '4' in qm_str_label:\n",
    "        #         label_line_map[qm_str_label] = '-.'\n",
    "        # otherwise, assume the string starts with '\\sigma' (multi-spin interaction)\n",
    "        else:\n",
    "            label_line_map[qm_str_label] = '-'\n",
    "\n",
    "    return label_line_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07960a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  PLOTTING FUNCTIONS\n",
    "#----------------------------------------------------------------------\n",
    "def plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot=None, threshold=0.01, print_initial_config = False):\n",
    "    classical_param_values = np.linspace(start, end, steps)\n",
    "    _, interaction_labels, interaction_weights = generate_interaction_matrices(N)\n",
    "\n",
    "    label_color_map = color_dictionary(N)\n",
    "    label_line_map  = line_type_dictionary(N)\n",
    "\n",
    "    # create plots for the changed parameters\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    # find quantum parameters that have changed more than the threshold\n",
    "    changed_params_booleans = np.abs(np.max(quantum_params, axis=0) - np.min(quantum_params, axis=0)) > threshold\n",
    "\n",
    "    # get tuple labels to plot\n",
    "    tuples_to_plot = np.array(interaction_labels)[changed_params_booleans]\n",
    "\n",
    "    #convert tuple labels to strings\n",
    "    qm_str_labels_to_plot = [qm_interaction_label_to_string(label) for label in tuples_to_plot]\n",
    "\n",
    "    #sort them alphabetically and numerically\n",
    "    sorted_qm_str_labels_to_plot = sorted(qm_str_labels_to_plot, key=lambda x: (x[0].isalpha(), x))\n",
    "\n",
    "    #convert them back to tuple labels\n",
    "    sorted_tuples_to_plot = [qm_string_to_interaction_label(string, N) for string in sorted_qm_str_labels_to_plot]\n",
    "\n",
    "    for label in sorted_tuples_to_plot:\n",
    "        qm_str_label = qm_interaction_label_to_string(label)\n",
    "        tuple_to_idx = list(interaction_weights).index(label)\n",
    "        qm_param_values = np.array(quantum_params)[:, tuple_to_idx]\n",
    "\n",
    "        if qm_params_to_plot is None or qm_str_label in qm_params_to_plot:\n",
    "            color = label_color_map[qm_str_label]\n",
    "            line  = label_line_map[qm_str_label]\n",
    "            plt.plot(classical_param_values, qm_param_values, linestyle = line, label=qm_str_label, color=color)\n",
    "\n",
    "    classical_param_index_str = \"\".join(str(idx + 1) for idx in index)  # convert to proper string for visualization\n",
    "    plt.title(f'Variation of Quantum Parameters with Classical Parameter ${param}_{{ {classical_param_index_str} }}$')\n",
    "    plt.xlabel(f'${param}_{{ {classical_param_index_str} }}$')\n",
    "    plt.ylabel('Quantum Parameters')\n",
    "    \n",
    "    if print_initial_config:\n",
    "        classical_param_index_str = \"\".join(str(idx + 1) for idx in index)  # convert to proper string for visualization\n",
    "        classical_param_index_str_reverse = \"\".join(str(idx + 1) for idx in index[::-1])  # convert to proper string for visualization\n",
    "\n",
    "        print_sweep_param = f'${param}_{{ {classical_param_index_str} }}$'\n",
    "        print_sweep_param_conj = f'${param}_{{ {classical_param_index_str_reverse} }}$'\n",
    "\n",
    "        w_print = w.astype(str)\n",
    "        J_print = J.astype(str)\n",
    "        h_print = h.astype(str)\n",
    "\n",
    "        # update the corresponding parameter\n",
    "        if param == 'w':\n",
    "            w_print[index] = print_sweep_param\n",
    "            w_print[index[::-1]] = print_sweep_param_conj    # update symmetric element\n",
    "        elif param == 'J':\n",
    "            J_print[index] = print_sweep_param\n",
    "            J_print[index[::-1]] = print_sweep_param_conj    # update symmetric element\n",
    "        elif param == 'h':\n",
    "            h_print[index[0]] = print_sweep_param\n",
    "        \n",
    "        # print initial parameter configuration as matrices\n",
    "        plt.text(\n",
    "            1.02, 0.8,  # Adjust the x-coordinate (1.02) and y-coordinate (0.5) to position the text\n",
    "            f'Classical Parameters\\n\\nw:\\n{w_print}\\n\\nJ:\\n{J_print}\\n\\nh:\\n{h_print}',\n",
    "            verticalalignment='center', horizontalalignment='left',\n",
    "            transform=plt.gca().transAxes,\n",
    "            color='black', fontsize=10, fontfamily='monospace',\n",
    "            bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'),\n",
    "        )\n",
    "        # move the legend outside the figure and position it below the upper right corner\n",
    "        if qm_params_to_plot is None:\n",
    "            legend = plt.legend(loc='lower right', bbox_to_anchor=(1.112, 0), borderaxespad=0.)\n",
    "            \n",
    "        elif any('$J' in str for str in  qm_params_to_plot) or any('$\\s' in str for str in  qm_params_to_plot):\n",
    "            legend = plt.legend(loc='lower right', bbox_to_anchor=(1.112, 0), borderaxespad=0.)\n",
    "        else:\n",
    "            legend = plt.legend(loc='lower right', bbox_to_anchor=(1.107, 0), borderaxespad=0.)\n",
    "\n",
    "        # set the font size of the legend\n",
    "        legend.get_frame().set_linewidth(0.5)\n",
    "        for text in legend.get_texts():\n",
    "            text.set_fontsize(12)\n",
    "    else:\n",
    "        plt.legend()\n",
    "    plt.tight_layout()  # ensures the legend and text do not overlap with the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_inverse_mapping(w_vals, J_vals, h_vals, start, end, steps, quantum_param_label, w_qm, learning_rate_bm, maxiter_bm, classical_params_to_plot = None, threshold=0.01):\n",
    "    quantum_param_values = np.linspace(start, end, steps)\n",
    "\n",
    "    # find classical parameters that have changed sufficiently\n",
    "    changed_w = np.abs(np.max(w_vals, axis = 0) - np.min(w_vals, axis=0)) > threshold\n",
    "    changed_J = np.abs(np.max(J_vals, axis = 0) - np.min(J_vals, axis=0)) > threshold\n",
    "    changed_h = np.abs(np.max(h_vals, axis = 0) - np.min(h_vals, axis=0)) > threshold\n",
    "\n",
    "    # flatten parameters\n",
    "    w_vals = np.array(w_vals).reshape(steps,N**4)\n",
    "    J_vals = np.array(J_vals).reshape(steps,N**2)\n",
    "    h_vals = np.array(h_vals)\n",
    "    changed_w = changed_w.flatten()\n",
    "    changed_J = changed_J.flatten()\n",
    "    changed_h = changed_h.flatten()\n",
    "\n",
    "    # if specific parameters to plot are provided, use those\n",
    "    if classical_params_to_plot is not None:\n",
    "            print('this is not implemented yet!')\n",
    "\n",
    "    # create plots for the changed parameters\n",
    "    fig = plt.figure(figsize=(25, 6));     #  make plots\n",
    "    qm_str_label = qm_interaction_label_to_string(quantum_param_label) #get string label of sweep qm parameter\n",
    "\n",
    "    fig.suptitle(f'Variation of Classical Paramaters versus Quantum Parameter {qm_str_label}', fontsize=30, y = 1.1)\n",
    "    trans = mtransforms.ScaledTranslation(-20/72, 7/72, fig.dpi_scale_trans)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    for i, w_vals_changed in enumerate(w_vals[:,changed_w].T):\n",
    "        original_index = np.unravel_index(i, (2**N, 2**N))\n",
    "        classical_param_index_str =\"\".join(str(idx + 1) for idx in original_index) #convert to proper string for visualization\n",
    "        ax1.scatter(quantum_param_values, w_vals_changed, label= f'$w_{{ {classical_param_index_str} }}$', s = 15)\n",
    "    ax1.set_xlabel(f'{qm_str_label}', fontsize=20)\n",
    "    ax1.set_ylabel('$w$ parameters', fontsize=20)\n",
    "    ax1.legend()\n",
    "    ax1.text(0, 1.0, 'A.)', transform=ax1.transAxes + trans, fontsize='large',fontweight ='bold', va='bottom', fontfamily='sans-serif')\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    for i, J_vals_changed in enumerate(J_vals[:,changed_J].T):\n",
    "        original_index = np.unravel_index(i, (N, N))\n",
    "        classical_param_index_str =\"\".join(str(idx + 1) for idx in original_index) #convert to proper string for visualization\n",
    "        ax2.scatter(quantum_param_values, J_vals_changed, label= f'$J_{{ {classical_param_index_str} }}$', s = 15)\n",
    "    ax2.set_xlabel(f'{qm_str_label}', fontsize=20)\n",
    "    ax2.set_ylabel('$J$ parameters', fontsize=20)\n",
    "    ax2.legend()\n",
    "    ax2.text(0, 1.0, 'B.)', transform=ax2.transAxes + trans, fontsize='large',fontweight ='bold', va='bottom', fontfamily='sans-serif')\n",
    "\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    plt.figure(figsize=(4,3))\n",
    "    for i, h_vals_changed in enumerate(h_vals[:,changed_h].T):\n",
    "        original_index = np.unravel_index(i, (N, N))\n",
    "        classical_param_index_str =\"\".join(str(idx + 1) for idx in original_index) #convert to proper string for visualization\n",
    "        ax3.scatter(quantum_param_values, h_vals_changed, label= f'$h_{{ {classical_param_index_str} }}$', s = 15)\n",
    "    ax3.set_xlabel(f'{qm_str_label}', fontsize=20)\n",
    "    ax3.set_ylabel('$h$ parameters', fontsize=20)\n",
    "    ax3.legend()\n",
    "    ax3.text(0, 1.0, 'B.)', transform=ax3.transAxes + trans, fontsize='large',fontweight ='bold', va='bottom', fontfamily='sans-serif')\n",
    "\n",
    "\n",
    "def plot_combined_dynamics(trajectory, N, w_qm = None, w = None, J = None, h = None, title = 'Dyamics', print_inferred_params = False,  print_only_nonzero = False):\n",
    "    fig, (ax1,ax2)= plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Plot for the system's evolution through states\n",
    "    states = [(''.join(['0' if spin == -1 else '1' for spin in s])) for s in trajectory]  # convert spins to binary\n",
    "    unique_states = sorted(set(states))\n",
    "    state_indices = [unique_states.index(state) for state in states]\n",
    "    \n",
    "    ax1.step(range(len(state_indices)), state_indices)\n",
    "    ax1.set_yticks(range(len(unique_states)))\n",
    "    ax1.set_yticklabels(unique_states)\n",
    "    ax1.set_title(\"System's evolution through states\")\n",
    "    ax1.set_xlabel('Time step')\n",
    "    ax1.set_ylabel('State')\n",
    "    \n",
    "    # Plot for the spins' evolution\n",
    "    offset_labels = []\n",
    "    y_ticks = []\n",
    "    for i in range(N):\n",
    "        spin_trajectory = trajectory[:, i] - i * 3\n",
    "        ax2.step(range(len(spin_trajectory)), spin_trajectory, label=f'Spin {i+1}')\n",
    "        offset_labels += ['0', '1']\n",
    "        y_ticks += [(i*3 - 1), (i*3 +1)]\n",
    "        \n",
    "    ax2.set_title(\"Spins' evolution\")\n",
    "    ax2.set_xlabel('Time step')\n",
    "    ax2.set_ylabel('Spin value (with offset)')\n",
    "    ax2.set_yticks(y_ticks)\n",
    "    ax2.set_yticklabels(offset_labels)\n",
    "    ax2.legend(loc='best')\n",
    "    ax2.plot()\n",
    "\n",
    "    if w_qm is not None:\n",
    "        _, interaction_labels, interaction_weights = generate_interaction_matrices(N)\n",
    "\n",
    "        #convert tuple labels to strings\n",
    "        qm_str_labels = [qm_interaction_label_to_string(label) for label in np.array(interaction_labels)]\n",
    "\n",
    "        #sort them alphabetically and numerically\n",
    "        sorted_qm_str_labels = sorted(qm_str_labels, key=lambda x: (x[0].isalpha(), x))\n",
    "\n",
    "        #convert them back to tuple labels\n",
    "        sorted_tuples = [qm_string_to_interaction_label(string, N) for string in sorted_qm_str_labels]\n",
    "\n",
    "        str_to_print = ''\n",
    "        for label in sorted_tuples:\n",
    "            qm_str_label = qm_interaction_label_to_string(label)\n",
    "            tuple_to_idx = list(interaction_weights).index(label)\n",
    "            quantum_param_values = np.array(w_qm)[tuple_to_idx]\n",
    "            label_tuple = tuple(label)\n",
    "            num_y = label_tuple.count('Y')\n",
    "            if not qm_str_label.startswith('$\\l') and not num_y % 2 == 1:\n",
    "                if print_only_nonzero:\n",
    "                    if not np.allclose(quantum_param_values, 0):\n",
    "                        str_to_print += f'{qm_str_label}: {quantum_param_values}\\n'\n",
    "                else:\n",
    "                    str_to_print += f'{qm_str_label}: {quantum_param_values}\\n'\n",
    "\n",
    "        ax2.text(\n",
    "            1.05, 0.8,  # Adjust the x-coordinate (1.02) and y-coordinate (0.5) to position the text\n",
    "            f'Quantum Parameters\\n\\n{str_to_print}' ,\n",
    "            verticalalignment='center', horizontalalignment='left',\n",
    "            transform=plt.gca().transAxes,\n",
    "            color='black', fontsize=10, fontfamily='monospace',\n",
    "            bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'),\n",
    "        )\n",
    "\n",
    "    if print_inferred_params:\n",
    "        w_print = np.array2string(w, formatter={'float_kind': lambda x: \"{:.5f}\".format(x)})\n",
    "        J_print = np.array2string(J, formatter={'float_kind': lambda x: \"{:.5f}\".format(x)})\n",
    "        h_print = np.array2string(h, formatter={'float_kind': lambda x: \"{:.5f}\".format(x)})\n",
    "\n",
    "        # print initial parameter configuration as matrices\n",
    "        ax2.text(\n",
    "            1.05, 0,  # Adjust the x-coordinate (1.02) and y-coordinate (0.5) to position the text\n",
    "            f'Inferred \\nClassical Parameters\\n\\nw:\\n{w_print} \\n\\nJ:\\n{J_print} \\n\\nh:\\n{h_print}',\n",
    "            verticalalignment='center', horizontalalignment='left',\n",
    "            transform=plt.gca().transAxes,\n",
    "            color='black', fontsize=10, fontfamily='monospace',\n",
    "            bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'),\n",
    "        )\n",
    "\n",
    "    plt.suptitle(title, fontsize=20, y = 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8733d622",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m# call the function\u001b[39;00m\n\u001b[1;32m     32\u001b[0m check_inversion_error_inverse(start, end, steps, quantum_param_label, w_qm, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n\u001b[0;32m---> 33\u001b[0m w_vals, J_vals, h_vals \u001b[39m=\u001b[39m analyze_inverse_parameter_mapping(start, end, steps, quantum_param_label, w_qm, learning_rate_bm,  maxiter_bm, classical_params_to_plot, threshold)\n\u001b[1;32m     34\u001b[0m plot_inverse_mapping(w_vals, J_vals, h_vals, start, end, steps, quantum_param_label, w_qm, learning_rate_bm, maxiter_bm, classical_params_to_plot, threshold)\n",
      "Cell \u001b[0;32mIn[78], line 57\u001b[0m, in \u001b[0;36manalyze_inverse_parameter_mapping\u001b[0;34m(start, end, steps, quantum_param_label, w_qm, learning_rate_bm, maxiter_bm, classical_params_to_plot, threshold)\u001b[0m\n\u001b[1;32m     54\u001b[0m w_qm[param_index] \u001b[39m=\u001b[39m value\n\u001b[1;32m     56\u001b[0m \u001b[39m# perform the inverse mapping [only plot the last iteration]\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m w, J, h \u001b[39m=\u001b[39m inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[39m# add to lists\u001b[39;00m\n\u001b[1;32m     60\u001b[0m w_vals\u001b[39m.\u001b[39mappend(w)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# initialize the qm parameters using the weight dictionary\n",
    "N = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(N)\n",
    "#set everything to zero\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# define the quantum parameter that will be varied\n",
    "quantum_param_label = ('X','X')\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = 0\n",
    "end = .8\n",
    "steps = 5\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_bm = .9\n",
    "maxiter_bm = 2**16\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .9\n",
    "maxiter_qbm = 2**16\n",
    "\n",
    "\n",
    "# specify the classical parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "classical_params_to_plot = None\n",
    "# plot_params = ['w_{12}', 'J_{14}', 'h_{2}'] #should work somehthing like this\n",
    "\n",
    "# specify the change threshold\n",
    "threshold = 0.01\n",
    "\n",
    "# call the function\n",
    "check_inversion_error_inverse(start, end, steps, quantum_param_label, w_qm, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "w_vals, J_vals, h_vals = analyze_inverse_parameter_mapping(start, end, steps, quantum_param_label, w_qm, learning_rate_bm,  maxiter_bm, classical_params_to_plot, threshold)\n",
    "plot_inverse_mapping(w_vals, J_vals, h_vals, start, end, steps, quantum_param_label, w_qm, learning_rate_bm, maxiter_bm, classical_params_to_plot, threshold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "783e3df4",
   "metadata": {},
   "source": [
    "# **Results Quantum-Classical Mapping**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2538cfb7",
   "metadata": {},
   "source": [
    "## Forward Reversibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5d7dad8",
   "metadata": {},
   "source": [
    "For all 3 systems, we can see that the forward mapping is reversible. This means that we can map from classical to quantum and back to classical and get the same result. This is a good sign, since it means that we can use the quantum system to represent the classical one and vice versa. The KL divergence between the two systems is also zero, which means that the two systems are identical(?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "856da6f8",
   "metadata": {},
   "source": [
    "### Reversibility for 2-qubits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d750f10",
   "metadata": {},
   "source": [
    "Since for a 2-qubit system, the Hamiltonian is a complete model, we would expect that the mapping $w_{cl} \\rarr w_{qm} \\rarr w_{cl}$ works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c291da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,4,4,4],\n",
    "              [4,0,4,4],\n",
    "              [4,4,0,4],\n",
    "              [4,4,4,0]], dtype=np.float64)\n",
    "J = np.array([[0,1],\n",
    "              [1,0]], dtype=np.float64)\n",
    "h = np.array([0, 2],  dtype=np.float64)\n",
    "\n",
    "# make sure w are large enough for normalized probabilities\n",
    "check_parameters(w,J,h)\n",
    "\n",
    "#intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .2\n",
    "maxiter_qbm = 2**12\n",
    "\n",
    "learning_rate_bm = .9\n",
    "maxiter_bm = 2**12\n",
    "\n",
    "# map forward and back. Set plot_convergence to True if you want to see the convergence plots\n",
    "w_qm = forward_mapping(w, J, h, learning_rate_qbm, maxiter_qbm, plot_convergence = False)\n",
    "W_recovered, w_recovered, J_recovered, h_recovered = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = False)\n",
    "\n",
    "print('Difference in initial and recovered parameters:')\n",
    "print(f'w: \\n {np.abs(w - w_recovered)}')\n",
    "print(f'J: \\n {np.abs(J - J_recovered)}')\n",
    "print(f'h: \\n {np.abs(h - h_recovered)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1197d3b",
   "metadata": {},
   "source": [
    "And so it does. Interestingly, for the same learning rate, the QBM converges WAY faster,but can only converge up to 1e-6. BM can converge all the way till 1e-14.  The QBM takes about 50 iterations to converge to 1e-6 while the BM takes ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c101d9c",
   "metadata": {},
   "source": [
    "### Reversibility for 3-qubits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2711261b",
   "metadata": {},
   "source": [
    "\n",
    "Another open question is if we are be able to invert the forward mapping for a non-complete Hamiltonian (i.e. N > 2). Let's try for a 3-qubit system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09735953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 3\n",
    "w = np.array([[0,4,4,4,4,4,4,4],\n",
    "              [4,0,4,4,4,4,4,4],\n",
    "              [4,4,0,4,4,4,4,4],\n",
    "              [4,4,4,0,4,4,4,4],\n",
    "              [4,4,4,4,0,4,4,4],\n",
    "              [4,4,4,4,4,0,4,4],\n",
    "              [4,4,4,4,4,4,0,4],               \n",
    "              [4,4,4,4,4,4,4,0]], dtype=np.float64)\n",
    "J = np.array([[0,1,.2],\n",
    "              [1,0,.8],\n",
    "              [.2,.8,0]], dtype=np.float64)\n",
    "h = np.array([.3, .6, .2], dtype=np.float64)\n",
    "\n",
    "print(w.shape)\n",
    "check_parameters(w,J,h)\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "#intialize the optimal learning parameters for 3-qubits\n",
    "learning_rate_qbm = .9\n",
    "maxiter_qbm = 2**10\n",
    "\n",
    "learning_rate_bm = .9\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "# map forward and back. Set plot_convergence to True if you want to see the convergence plots\n",
    "w_qm = forward_mapping(w, J, h, learning_rate_qbm, maxiter_qbm, plot_convergence = True, perform_checks = False)\n",
    "W_recovered, w_recovered, J_recovered, h_recovered = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = False)\n",
    "\n",
    "print('Difference in initial and recovered parameters:')\n",
    "print(f'w: \\n {np.abs(w - w_recovered)}')\n",
    "print(f'J: \\n {np.abs(J - J_recovered)}')\n",
    "print(f'h: \\n {np.abs(h - h_recovered)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7920a520",
   "metadata": {},
   "source": [
    "- We can recover the parameters, pretty accurately, even though we don't use a complete Hamiltonian. Note that we do have to turn of the checking of valid W and rho because some values get slighly negative due inaccuracies.\n",
    "- Don't quite understand what happens with the KL-divergence though. This effect seems to occur no matter how low a learning rate is chosen (e.g. for  $\\alpha_{QBM} = 0.001$ this still happens)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5834da12",
   "metadata": {},
   "source": [
    "### Reversibility for 4-qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa133548",
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_run = 1 #skip this due to long computation time\n",
    "if dont_run == 1: \n",
    "\n",
    "    # initialize the classical parameters\n",
    "    N = 4\n",
    "    w = np.array([[0,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\n",
    "                [4,0,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\n",
    "                [4,4,0,4,4,4,4,4,4,4,4,4,4,4,4,4],\n",
    "                [4,4,4,0,4,4,4,4,4,4,4,4,4,4,4,4],\n",
    "                [4,4,4,4,0,4,4,4,4,4,4,4,4,4,4,4],\n",
    "                [4,4,4,4,4,0,4,4,4,4,4,4,4,4,4,4],\n",
    "                [4,4,4,4,4,4,0,4,4,4,4,4,4,4,4,4],               \n",
    "                [4,4,4,4,4,4,4,0,4,4,4,4,4,4,4,4],\n",
    "                [4,4,4,4,4,4,4,4,0,4,4,4,4,4,4,4],\n",
    "                [4,4,4,4,4,4,4,4,4,0,4,4,4,4,4,4],\n",
    "                [4,4,4,4,4,4,4,4,4,4,0,4,4,4,4,4],\n",
    "                [4,4,4,4,4,4,4,4,4,4,4,0,4,4,4,4],\n",
    "                [4,4,4,4,4,4,4,4,4,4,4,4,0,4,4,4],\n",
    "                [4,4,4,4,4,4,4,4,4,4,4,4,4,0,4,4],\n",
    "                [4,4,4,4,4,4,4,4,4,4,4,4,4,4,0,4],               \n",
    "                [4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,0]], dtype=np.float64)\n",
    "    \n",
    "    J = np.array([[0,.1,.2,.3],\n",
    "                  [.1,0,.1,.3],\n",
    "                  [.2,.1,0,.2],\n",
    "                  [.3,.3,.2,0]],      dtype=np.float64)\n",
    "    \n",
    "    h = np.array([.1, .2, .1, .2],        dtype=np.float64)\n",
    "\n",
    "    check_parameters(w,J,h)\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "    #intialize the optimal learning parameters for 4-qubits\n",
    "    learning_rate_qbm = .1\n",
    "    maxiter_qbm = 2**11\n",
    "\n",
    "    learning_rate_bm = .004\n",
    "    maxiter_bm = 2**22\n",
    "\n",
    "    # map forward and back. Set plot_convergence to True if you want to see the convergence plots\n",
    "    w_qm = forward_mapping(w, J, h, learning_rate_qbm, maxiter_qbm, plot_convergence = True, perform_checks = False)\n",
    "    W_recovered, w_recovered, J_recovered, h_recovered = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = True, perform_checks = False)\n",
    "\n",
    "    print('Difference in initial and recovered parameters:')\n",
    "    print(f'w: \\n {np.abs(w - w_recovered)}')\n",
    "    print(f'J: \\n {np.abs(J - J_recovered)}')\n",
    "    print(f'h: \\n {np.abs(h - h_recovered)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_recovered = compute_transition_matrix(w_recovered, h_recovered, J_recovered)\n",
    "W = compute_transition_matrix(w, h, J)\n",
    "print(W_recovered)\n",
    "# print(f'Difference between W and W_recovered: {np.abs(W - W_recovered)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f4a628",
   "metadata": {},
   "source": [
    "## Forward Homogenous Mappings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b0893bd",
   "metadata": {},
   "source": [
    "We can however insert the full resolution W directly in the QBM route and get quantum parameters that might map to non-equilibrium effects. We only can't invert the mapping."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9704ffa",
   "metadata": {},
   "source": [
    "### Results 2-qubits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5a12bb9",
   "metadata": {},
   "source": [
    "#### Varying J in homogenous system with zero biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "N = 2\n",
    "w = np.array([[0,4,4,4],\n",
    "              [4,0,4,4],\n",
    "              [4,4,0,4],\n",
    "              [4,4,4,0]], dtype=np.float64)\n",
    "J = np.array([[0, 0],\n",
    "              [0, 0]],    dtype=np.float64)\n",
    "h = np.array([1e-10, 1e-10],    dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'J'\n",
    "index = (0, 1)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -2.15\n",
    "end = 2.15\n",
    "steps = 100\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**11\n",
    "\n",
    "#only relevant for checking if the mapping is invertible\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "# qm_params_to_plot = ['$h_{1}^{Z}$', '$h_{2}^{Z}$']\n",
    "# qm_params_to_plot = ['$h_{1}^{X}$', '$h_{2}^{X}$']\n",
    "qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$', '$h_{1}^{X}$', '$h_{2}^{X}$']\n",
    "threshold = 0.01  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25492f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,interaction_labels,interaction_weights = generate_interaction_matrices(N)\n",
    "print(interaction_labels)\n",
    "\n",
    "Jxx = np.array(quantum_params)[:, 5]\n",
    "Jyy = np.array(quantum_params)[:, 10]\n",
    "Jzz = np.array(quantum_params)[:, 15]\n",
    "\n",
    "classical_param_values = np.linspace(start, end, steps)\n",
    "\n",
    "plt.plot(classical_param_values, Jxx, label = '$J_{12}^{XX}$')\n",
    "plt.plot(classical_param_values, Jyy, label = '$J_{12}^{YY}$')\n",
    "# plt.plot(classical_param_values, Jzz, label = '$J_{12}^{ZZ}$', color = 'green')\n",
    "# plt.plot(classical_param_values, Jxx - Jyy, label = '$J_{12}^{X} - J_{12}^{Y}$', color = 'green')\n",
    "plt.legend()\n",
    "plt.title('Variation of Quantum Parameters with Classical Parameter $J_{12}$')\n",
    "plt.xlabel('$J_{12}$')\n",
    "plt.ylabel('Quantum Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc1e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, -1.5],\n",
    "              [-1.5, 0]],   dtype=np.float64)\n",
    "h = np.array([1e-10, 1e-10],    dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "W = compute_transition_matrix(w, h, J)\n",
    "trajectory = simulate_dynamics(W, 100, N)\n",
    "plot_combined_dynamics(trajectory, N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2828ee4e",
   "metadata": {},
   "source": [
    "#### Varying J in homogenous system with small biases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, 1],\n",
    "              [1, 0]],     dtype=np.float64)\n",
    "h = np.array([1e-6 ,1e-6],   dtype=np.float64)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'J'\n",
    "index = (0, 1)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -2.15\n",
    "end = 2.15\n",
    "steps = 100\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**22\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "# qm_params_to_plot = None\n",
    "qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "# qm_params_to_plot = ['$h_{1}^{Z}$', '$h_{2}^{Z}$']\n",
    "qm_params_to_plot = ['$h_{1}^{X}$', '$h_{2}^{X}$']\n",
    "threshold = 0.001  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, 2],\n",
    "              [2, 0]],   dtype=np.float64)\n",
    "h = np.array([.1 ,.1],   dtype=np.float64)\n",
    "\n",
    "W = compute_transition_matrix(w, h, J)\n",
    "trajectory = simulate_dynamics(W, 100, N)\n",
    "plot_combined_dynamics(trajectory, N)\n",
    "\n",
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[3, 3], \n",
    "              [3, 3]],   dtype=np.float64)\n",
    "J = np.array([[0, 0],\n",
    "              [0, 0]],   dtype=np.float64)\n",
    "h = np.array([.1 ,.1],   dtype=np.float64)\n",
    "\n",
    "W = compute_transition_matrix(w, h, J)\n",
    "trajectory = simulate_dynamics(W, 100, N)\n",
    "plot_combined_dynamics(trajectory, N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e98ae218",
   "metadata": {},
   "source": [
    "#### Varying J in homogenous system with large biases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2756fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, 0],\n",
    "              [0, 0]],   dtype=np.float64)\n",
    "h = np.array([.8,-.8],   dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'J'\n",
    "index = (0, 1)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -1.15\n",
    "end = .8\n",
    "steps = 100\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**22\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "qm_params_to_plot = ['$J_{12}^{XZ}$', '$J_{12}^{ZX}$']\n",
    "\n",
    "# qm_params_to_plot = ['$h_{1}^{Z}$', '$h_{2}^{Z}$']\n",
    "# qm_params_to_plot = ['$h_{1}^{X}$', '$h_{2}^{X}$']\n",
    "threshold = 0.0001  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16cff3ad",
   "metadata": {},
   "source": [
    "#### Varying h in homogenous system without interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf84b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, 0],\n",
    "              [0, 0]],   dtype=np.float64)\n",
    "h = np.array([0,0],      dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'h'\n",
    "index = (0, 0)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -2\n",
    "end = 2\n",
    "steps = 100\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**22\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "# qm_params_to_plot = ['$h_{1}^{Z}$', '$h_{2}^{Z}$']\n",
    "# qm_params_to_plot = ['$h_{1}^{X}$', '$h_{2}^{X}$']\n",
    "# qm_params_to_plot = ['$h_{2}^{Z}$', '$J_{12}^{XZ}$']\n",
    "threshold = 0.01  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, 0],\n",
    "              [0, 0]],   dtype=np.float64)\n",
    "h = np.array([0,0],      dtype=np.float64)\n",
    "\n",
    "W = compute_transition_matrix(w, h, J)\n",
    "trajectory = simulate_dynamics(W, 1000, N)\n",
    "plot_combined_dynamics(trajectory, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf87cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, 0],\n",
    "              [0, 0]],   dtype=np.float64)\n",
    "h = np.array([-2,1e-6],      dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "W = compute_transition_matrix(w, h, J)\n",
    "trajectory = simulate_dynamics(W, 500, N)\n",
    "plot_combined_dynamics(trajectory, N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4246b7b2",
   "metadata": {},
   "source": [
    "#### Varying h in homogenous system with small interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84faa786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, .2],\n",
    "              [.2, 0]],   dtype=np.float64)\n",
    "h = np.array([-2,0],      dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, .2],\n",
    "              [.2, 0]],   dtype=np.float64)\n",
    "h = np.array([0,0],      dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'h'\n",
    "index = (0, 0)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -2\n",
    "end = 2\n",
    "steps = 100\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**22\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "# qm_params_to_plot = ['$h_{1}^{Z}$', '$h_{2}^{Z}$']\n",
    "# qm_params_to_plot = ['$h_{1}^{X}$', '$h_{2}^{X}$']\n",
    "# qm_params_to_plot = ['$h_{2}^{Z}$', '$J_{12}^{XZ}$']\n",
    "threshold = 0.1  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f401661b",
   "metadata": {},
   "source": [
    "#### Varying h in homogenous system with large interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4166fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, 1],\n",
    "              [1, 0]],   dtype=np.float64)\n",
    "h = np.array([0,0],      dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'h'\n",
    "index = (0, 0)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -1.5\n",
    "end = 1.5\n",
    "steps = 100\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**22\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "# qm_params_to_plot = ['$h_{1}^{Z}$', '$h_{2}^{Z}$']\n",
    "# qm_params_to_plot = ['$h_{1}^{X}$', '$h_{2}^{X}$']\n",
    "# qm_params_to_plot = ['$h_{2}^{Z}$', '$J_{12}^{XZ}$']\n",
    "threshold = 0.01  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a61bf6f",
   "metadata": {},
   "source": [
    "#### Varying w in homogenous system without interactions or biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf42235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]], dtype=np.float64)\n",
    "J = np.array([[0, 0],\n",
    "              [0, 0]],   dtype=np.float64)\n",
    "h = np.array([0,0],      dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7faa4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[0,3,3,3],\n",
    "              [3,0,3,3],\n",
    "              [3,3,0,3],\n",
    "              [3,3,3,0]],  dtype=np.float64)\n",
    "J = np.array([[0, 0.1],\n",
    "              [0.1, 0]],   dtype=np.float64)\n",
    "h = np.array([1e-6,1e-6],  dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'w'\n",
    "index = (0, 3)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = 2\n",
    "end = 5\n",
    "steps = 100\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**22\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "# qm_params_to_plot = ['$h_{1}^{Z}$', '$h_{2}^{Z}$']\n",
    "# qm_params_to_plot = ['$h_{1}^{X}$', '$h_{2}^{X}$']\n",
    "# qm_params_to_plot = ['$h_{2}^{Z}$', '$J_{12}^{XZ}$']\n",
    "threshold = 0.001  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,interaction_labels,interaction_weights = generate_interaction_matrices(N)\n",
    "# print(interaction_labels)\n",
    "\n",
    "Jxx = np.array(quantum_params)[:, 5]\n",
    "Jyy = np.array(quantum_params)[:, 10]\n",
    "Jzz = np.array(quantum_params)[:, 15]\n",
    "\n",
    "classical_param_values = np.linspace(start, end, steps)\n",
    "\n",
    "plt.plot(classical_param_values, Jxx, label = '$J_{12}^{XX}$')\n",
    "plt.plot(classical_param_values, Jyy, label = '$J_{12}^{YY}$')\n",
    "# plt.plot(classical_param_values, Jzz, label = '$J_{12}^{ZZ}$', color = 'green')\n",
    "# plt.plot(classical_param_values, Jxx - Jyy, label = '$J_{12}^{X} - J_{12}^{Y}$', color = 'red')\n",
    "# plt.plot(classical_param_values, Jxx + Jyy, label = '$J_{12}^{X} + J_{12}^{Y}$')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Variation of quantum parameters when changing time scale of double spin flips $w_{12}$')\n",
    "plt.xlabel('$w_{12}$')\n",
    "plt.ylabel('Quantum Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227885d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,interaction_labels,interaction_weights = generate_interaction_matrices(N)\n",
    "print(interaction_labels)\n",
    "\n",
    "hx = np.array(quantum_params)[:, 4]\n",
    "\n",
    "\n",
    "classical_param_values = np.linspace(start, end, steps)\n",
    "\n",
    "# plt.plot(classical_param_values, hx, label = '$h_{1}^{X}$', color = 'Hotpink')\n",
    "# plt.plot(classical_param_values, Jyy, label = '$J_{12}^{YY}$')\n",
    "# plt.plot(classical_param_values, Jzz, label = '$J_{12}^{ZZ}$', color = 'green')\n",
    "# plt.plot(classical_param_values, Jxx - Jyy, label = '$J_{12}^{XX} - J_{12}^{YY}$', color = 'red')\n",
    "plt.legend()\n",
    "plt.title('Variation of quantum parameters when changing time scale of single spin flips $w_{1}$')\n",
    "plt.xlabel('$w_{1}$')\n",
    "plt.ylabel('Quantum Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[6, 4], \n",
    "              [4, 4]],   dtype=np.float64)\n",
    "J = np.array([[0, 1],\n",
    "              [1, 0]],   dtype=np.float64)\n",
    "h = np.array([1e-6,1e-6],      dtype=np.float64)\n",
    "\n",
    "#check that parameters are valid\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "W = compute_transition_matrix(w, h, J)\n",
    "trajectory = simulate_dynamics(W, 500, N)\n",
    "plot_combined_dynamics(trajectory, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5833f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfc2cd43",
   "metadata": {},
   "source": [
    "#### Varying w in homogenous system with interactions and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacfb94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c916c38",
   "metadata": {},
   "source": [
    "### Results 3-qubit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b94269a",
   "metadata": {},
   "source": [
    "#### Varying J in homogenous system with zero biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69dc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[3, 3], \n",
    "              [3, 3]],   dtype=np.float64)\n",
    "J = np.array([[0, 1],\n",
    "              [1, 0]],   dtype=np.float64)\n",
    "h = np.array([1e-6,1e-6],      dtype=np.float64)\n",
    "\n",
    "#check if we got valid parameters\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'J'\n",
    "index = (0, 1)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -1.4\n",
    "end = 1.4\n",
    "steps = 30\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**11\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "# qm_params_to_plot = ['$J_{12}^{ZZ}$'] \n",
    "\n",
    "threshold = 0.01  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91180bd8",
   "metadata": {},
   "source": [
    "Smaller biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "N = 3\n",
    "w = np.array([[3, 3 ,3],\n",
    "              [3, 3, 3],\n",
    "              [3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "J = np.array([[0, 0, 0],\n",
    "              [0 ,0, 0],\n",
    "              [0, 0, 0]], dtype = np.float64)\n",
    "\n",
    "h = np.array([.000001, .000001, .000001],   dtype = np.float64)\n",
    "\n",
    "#check if we got valid parameters\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'J'\n",
    "index = (1, 2)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -.7\n",
    "end = .7\n",
    "steps = 30\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**11\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = ['$J_{12}^{ZZ}$', '$J_{12}^{YY}$'] \n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "threshold = 0.01  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ca54524",
   "metadata": {},
   "source": [
    "#### Varying J in homogenous system with small biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "N = 3\n",
    "w = np.array([[3, 3 ,3],\n",
    "              [3, 3, 3],\n",
    "              [3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "J = np.array([[0, 0, 0],\n",
    "              [0 ,0, 0],\n",
    "              [0, 0, 0]], dtype = np.float64)\n",
    "\n",
    "h = np.array([.75, .75, .75],   dtype = np.float64)\n",
    "\n",
    "#check if we got valid parameters\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'J'\n",
    "index = (0, 1)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = 0\n",
    "end = .70\n",
    "steps = 30\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**11\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = ['$J_{12}^{ZZ}$', '$J_{12}^{YY}$'] \n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "# qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "threshold = 0.01  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a65f03cb",
   "metadata": {},
   "source": [
    "#### Varying J in homogenous system with large biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fae6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "N = 3\n",
    "w = np.array([[3, 3 ,3],\n",
    "              [3, 3, 3],\n",
    "              [3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "J = np.array([[0, 0, 0],\n",
    "              [0 ,0, 0],\n",
    "              [0, 0, 0]], dtype = np.float64)\n",
    "\n",
    "h = np.array([1.5 ,1e-10, 1e-10],   dtype = np.float64)\n",
    "\n",
    "#check if we got valid parameters\n",
    "check_parameters(w, J, h)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c31885a",
   "metadata": {},
   "source": [
    "#### Varying h in homogenous system without interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "N = 3\n",
    "w = np.array([[3, 3 ,3],\n",
    "              [3, 3, 3],\n",
    "              [3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "J = np.array([[0, 0, 0],\n",
    "              [0 ,0, 0],\n",
    "              [0, 0, 0]], dtype = np.float64)\n",
    "\n",
    "h = np.array([0 ,1e-10, 1e-10],   dtype = np.float64)\n",
    "\n",
    "#check if we got valid parameters\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'h'\n",
    "index = (0, 0)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -1.5\n",
    "end = 1.5\n",
    "steps = 30\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**11\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "# qm_params_to_plot = ['$J_{12}^{ZZ}$'] \n",
    "\n",
    "threshold = 0.1  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03724110",
   "metadata": {},
   "source": [
    "#### Varying h in homogenous system with small interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34293139",
   "metadata": {},
   "source": [
    "#### Varying h in homogenous system with large interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12f9f1e3",
   "metadata": {},
   "source": [
    "#### Varying w in homogenous system without interactions or biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6101fcc8",
   "metadata": {},
   "source": [
    "#### Varying w in homogenous system with interactions and biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5205472",
   "metadata": {},
   "source": [
    "### Results 4-qubit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81abdef1",
   "metadata": {},
   "source": [
    "#### Varying J in homogenous system with zero biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aafa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "    N = 4\n",
    "    w = np.array([[1, 1 ,1, 1],\n",
    "                  [1, 1, 1, 1],\n",
    "                  [1, 1, 1, 1],\n",
    "                  [1, 1, 1, 1]], dtype = np.float64)\n",
    "\n",
    "    J = np.array([[0, 0, 0, 0],\n",
    "                  [0 ,0, 0, 0],\n",
    "                  [0 ,0, 0, 0],\n",
    "                  [0, 0, 0, 0]],    dtype = np.float64)\n",
    "\n",
    "    h = np.array([1e-7, 1e-7, 1e-7, 1e-7],dtype = np.float64)\n",
    "    check_parameters(w,J,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_run =  False #skip this due to long computation time\n",
    "if not dont_run: \n",
    "    # initialize the parameters\n",
    "    N = 4\n",
    "    w = np.array([[3, 3 ,3, 3],\n",
    "                  [3, 3, 3, 3],\n",
    "                  [3, 3, 3, 3],\n",
    "                  [3, 3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "    J = np.array([[0, 0, 0, 0],\n",
    "                  [0 ,0, 0, 0],\n",
    "                  [0 ,0, 0, 0],\n",
    "                  [0, 0, 0, 0]],    dtype = np.float64)\n",
    "\n",
    "    h = np.array([1e-7, 1e-7, 1e-7, 1e-7],dtype = np.float64)\n",
    "    check_parameters(w,J,h)\n",
    "\n",
    "    # define the start, end and step size for the parameter change\n",
    "    start = -.9\n",
    "    end = .9\n",
    "    steps = 3\n",
    "\n",
    "    # define the parameter and index you want to change\n",
    "    param = 'J'\n",
    "    index = (0, 1)\n",
    "\n",
    "    #check the inversion error to see if trajectory is valid:\n",
    "    check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "    # intialize the optimal learning parameters for 2-qubits\n",
    "    learning_rate_qbm = .5\n",
    "    maxiter_qbm = 2**11\n",
    "\n",
    "    #only relevant for checking if the mapping is inverisble\n",
    "    learning_rate_bm = .8\n",
    "    maxiter_bm = 2**20\n",
    "\n",
    "    # specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "    qm_params_to_plot = None\n",
    "    # qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "    threshold = 0.1  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "    # call the function and plot the results\n",
    "    quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "    plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb99b858",
   "metadata": {},
   "source": [
    "#### Varying J in homogenous system with small biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b16cd748",
   "metadata": {},
   "source": [
    "#### Varying J in homogenous system with large biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fff28e4",
   "metadata": {},
   "source": [
    "#### Varying h in homogenous system without interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c028086",
   "metadata": {},
   "source": [
    "- Check biases <-> sigma z correspondence\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1cf5a40",
   "metadata": {},
   "source": [
    "#### Varying h in homogenous system with small interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "473dc919",
   "metadata": {},
   "source": [
    "#### Varying h in homogenous system with large interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b96d1a3",
   "metadata": {},
   "source": [
    "#### Varying w in homogenous system without interactions or biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e50ea1bc",
   "metadata": {},
   "source": [
    "Parameters relating purely to the dynamics of the classical system map to parameters of a static system?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97d6a811",
   "metadata": {},
   "source": [
    "#### Varying w in homogenous system with interactions and biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe852a82",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad22a550",
   "metadata": {},
   "source": [
    "## Assymetry and symmetric stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_detailed_balance(W):\n",
    "    \"\"\"\n",
    "    Check if the transition matrix W and stationary distribution pi satisfy the detailed balance condition.\n",
    "    \"\"\"\n",
    "    pi = steady_state(W)\n",
    "    n_states = W.shape[0]\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            assert np.isclose(W[i, j] * pi[i], W[j, i] * pi[j]), \"Transition matrix does not satisfy detailed balance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[8,9],\n",
    "              [9,8]], dtype=np.float64)\n",
    "J = np.array([[1,4],\n",
    "              [4,2]], dtype=np.float64)\n",
    "h = np.array([0, 2],  dtype=np.float64)\n",
    "\n",
    "W = compute_transition_matrix(w,h,J)\n",
    "\n",
    "check_detailed_balance(W)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a948670",
   "metadata": {},
   "source": [
    "We hypothesise that the assymetric part of the transition matrix maps to the imaginary components of the density matrix. We can check this by looking at the assymetric part of the transition matrix and see if it maps to the imaginary components of the density matrix.\n",
    "\n",
    "We can do so as follows:\n",
    "\n",
    "$\\Pi = diag(p(s))$  \n",
    "$F = \\Pi W$   Corresponds to probability flux, rewritten in terms of the transition matrix:\n",
    "$W = \\Pi^{-1} F$\n",
    "We can split the flux in a symmetric and assymetric part:  \n",
    "$F_{S} = \\frac{F + F^T}{2} , F_{A} = \\frac{F - F^T}{2} $  \n",
    "Which we can rewrite in terms of the symmetric and antisymmetric transition matrix:\n",
    "$W_{S} = \\Pi^{-1} F_{S}, W_{A} = \\Pi^{-1} F_{A}$  \n",
    "\n",
    "$W_{S} = \\Pi^{-1} \\frac{F + F^T}{2} = \\frac{\\Pi^{-1} F + \\Pi^{-1} F^T}{2} = \\frac{W + \\Pi W^{T} \\Pi^{-1}}{2}$\n",
    "\n",
    "With $F^T = (W \\Pi)^T = \\Pi^T W^T = \\Pi W^T$\n",
    "  \n",
    "Combining these results, we can write\n",
    "$W_{S/A} = \\left[\\frac{W \\pm \\Pi W^{T} \\Pi^{-1}}{2}\\right]$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58c709bd",
   "metadata": {},
   "source": [
    "Splitting W into a symmetric and assymetric part. Maybe we can split into a symmetric part and assymetric part and individually see to which QM parameters these transition matrices map back. In the symmetric case, we can also map it back to classical parameters.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f39b6522",
   "metadata": {},
   "source": [
    "\n",
    "We know that that the odd y-terms of the QM hamiltonian map to imaginary parts. So if we can find this link, we can link the odd y-terms to a dynamics that does not satisfy detailed balance, which would be interesting. Then we know other qm-parameters that map to dynamical classical parameters.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f522821",
   "metadata": {},
   "source": [
    "Deconstruct W in a symmetric and assymetric part and check if the assymmetric part corresponds to imaginary components of the density matrix "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd58139c",
   "metadata": {},
   "source": [
    "Also:  define a non-detailed balance classical W and see to what parameters they map. The mapping won’t be invertible, but that's okay."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4da3da8",
   "metadata": {},
   "source": [
    "## Rescaling the 2-qubit forward mappings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34c92a45",
   "metadata": {},
   "source": [
    "If both interactions are independent we can write the density matrix as a tensor product of the two qubit density matrices:\n",
    "\n",
    "$\\hat{eta}_{ij} = \\hat{\\rho}_i \\otimes \\hat{\\rho}_j$\n",
    "with  \n",
    "$\\eta_{i} = \\frac{e^{h_z \\hat{\\sigma_z} + h_x \\hat{\\sigma_x}}}{Z_i} = \\frac{1}{Z_i} \\left[ \\hat{I} \\cosh(\\sqrt{h_z^2 + h_x^2}) + \\frac{h_x}{\\sqrt{h_z^2 + h_x^2}} \\sinh(\\sqrt{h_z^2 + h_x^2}) \\hat{\\sigma_x} + \\frac{h_z}{\\sqrt{h_z^2 + h_x^2}} \\sinh(\\sqrt{h_z^2 + h_x^2}) \\hat{\\sigma_z} \\right] $\n",
    "\n",
    "[make eduardo check if this is true because I would not know or check it yourself if you dare]\n",
    "\n",
    "We can abbreviate $H = \\sqrt{h_z^2 + h_x^2}$ to write:\n",
    "$\\eta_{i} = \\frac{1}{Z_i} \\left[ \\hat{I} \\cosh(H) + \\frac{h_x}{H} \\sinh(H) \\hat{\\sigma_x} + \\frac{h_z}{H} \\sinh(H) \\hat{\\sigma_z} \\right] $\n",
    "\n",
    "BLEEEEH  \n",
    "$Z_1 = Z \\cosh(H) $\n",
    "\n",
    "Using all this shit we can derive the following expressions:  \n",
    "\n",
    "$\\frac{h_x}{H} \\tanh(H) = m_x = e^{-w}$ (1)  \n",
    "$\\frac{h_z}{H} \\tanh(H) = e^{-w} \\sinh(h_c)$ (2)  \n",
    "\n",
    "from which we can derive that   \n",
    "$h_x = \\frac{H}{\\tanh{H}} e^{-w} $  \n",
    "$h_z = \\frac{H}{\\tanh{H}} e^{-w} \\sinh(h_c)$  \n",
    "$\\frac{h_x}{h_z} = \\sinh(h_c)$  \n",
    "[$h_c$ is the classical bias]  \n",
    "\n",
    "Squaring and adding (1) and (2) gives:  \n",
    "$\\tanh^2(H) = e^{-2w}[1+\\sinh^2(h_c)]$  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72d10c41",
   "metadata": {},
   "source": [
    "## Forward Mapping for Heterogenous Systems ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d5c6210",
   "metadata": {},
   "source": [
    "With the different connectivities we discussed?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0513267",
   "metadata": {},
   "source": [
    "### 3 qubits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3829278",
   "metadata": {},
   "source": [
    "3D Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e02bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "N = 3\n",
    "w = np.array([[3, 3 ,3],\n",
    "              [3, 3, 3],\n",
    "              [3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "J = np.array([[0, 1, 0],\n",
    "              [1 ,0, 1],\n",
    "              [0, 1, 0]], dtype = np.float64)\n",
    "\n",
    "h = np.array([.1, .1, .1],   dtype = np.float64)\n",
    "\n",
    "#check if we got valid parameters\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'J'\n",
    "index = (0, 1)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -.7\n",
    "end = .7\n",
    "steps = 30\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**11\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "threshold = 0.01  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac39fffd",
   "metadata": {},
   "source": [
    "3 Bit Fully connected [triangle] [already done this, add hetrogenity in some other way?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfcbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "N = 3\n",
    "w = np.array([[3, 3 ,3],\n",
    "              [3, 3, 3],\n",
    "              [3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "J = np.array([[0, 1, 1],\n",
    "              [1 ,0, 1],\n",
    "              [0, 1, 0]], dtype = np.float64)\n",
    "\n",
    "h = np.array([.1, .1, .1],   dtype = np.float64)\n",
    "\n",
    "#check if we got valid parameters\n",
    "check_parameters(w, J, h)\n",
    "\n",
    "# define the classical parameter that will be varied\n",
    "param = 'J'\n",
    "index = (0, 1)\n",
    "\n",
    "# define the range over which the classical parameter will be varied\n",
    "start = -.7\n",
    "end = .7\n",
    "steps = 30\n",
    "\n",
    "# intialize the optimal learning parameters for 2-qubits\n",
    "learning_rate_qbm = .5\n",
    "maxiter_qbm = 2**11\n",
    "\n",
    "#only relevant for checking if the mapping is inverisble\n",
    "learning_rate_bm = .8\n",
    "maxiter_bm = 2**20\n",
    "\n",
    "#check the inversion error to see if trajectory is valid:\n",
    "check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "# specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "qm_params_to_plot = None\n",
    "# qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "threshold = 0.01  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "# call the function and plot the results\n",
    "quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcdcc49c",
   "metadata": {},
   "source": [
    "### 4 qubits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a181c9d",
   "metadata": {},
   "source": [
    "#### 4D Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ef3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "run =  0 #skip this due to long computation time\n",
    "if run == 1: \n",
    "    # initialize the parameters\n",
    "    N = 4\n",
    "    w = np.array([[3, 3 ,3, 3],\n",
    "                  [3, 3, 3, 3],\n",
    "                  [3, 3, 3, 3],\n",
    "                  [3, 3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "    J = np.array([[0, 1, 0, 0],\n",
    "                  [1 ,0, 1, 0],\n",
    "                  [0 ,1, 0, 1],\n",
    "                  [0, 0, 1, 0]],    dtype = np.float64)\n",
    "\n",
    "    h = np.array([1e-7, 1e-7, 1e-7, 1e-7],dtype = np.float64)\n",
    "    check_parameters(w,J,h)\n",
    "\n",
    "    # define the start, end and step size for the parameter change\n",
    "    start = -.9\n",
    "    end = .9\n",
    "    steps = 3\n",
    "\n",
    "    # define the parameter and index you want to change\n",
    "    param = 'J'\n",
    "    index = (0, 1)\n",
    "\n",
    "    #check the inversion error to see if trajectory is valid:\n",
    "    check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "    # intialize the optimal learning parameters for 2-qubits\n",
    "    learning_rate_qbm = .5\n",
    "    maxiter_qbm = 2**11\n",
    "\n",
    "    #only relevant for checking if the mapping is inverisble\n",
    "    learning_rate_bm = .8\n",
    "    maxiter_bm = 2**20\n",
    "\n",
    "    # specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "    qm_params_to_plot = None\n",
    "    # qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "    threshold = 0.1  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "    # call the function and plot the results\n",
    "    quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "    plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7be1c601",
   "metadata": {},
   "source": [
    "4D square (chain with periodic boundary conditions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0557953c",
   "metadata": {},
   "source": [
    "We assume numbering from top to bottom left to right   \n",
    "1 2  \n",
    "3 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run =  0 #skip this due to long computation time\n",
    "if run == 1: \n",
    "    # initialize the parameters\n",
    "    N = 4\n",
    "    w = np.array([[3, 3 ,3, 3],\n",
    "                  [3, 3, 3, 3],\n",
    "                  [3, 3, 3, 3],\n",
    "                  [3, 3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "    J = np.array([[0, 1, 1, 0],\n",
    "                  [1 ,0, 0, 1],\n",
    "                  [1 ,0, 0, 1],\n",
    "                  [0, 1, 1, 0]],    dtype = np.float64)\n",
    "\n",
    "    h = np.array([1e-7, 1e-7, 1e-7, 1e-7],dtype = np.float64)\n",
    "    check_parameters(w,J,h)\n",
    "\n",
    "    # define the start, end and step size for the parameter change\n",
    "    start = -.9\n",
    "    end = .9\n",
    "    steps = 3\n",
    "\n",
    "    # define the parameter and index you want to change\n",
    "    param = 'J'\n",
    "    index = (0, 1)\n",
    "\n",
    "    #check the inversion error to see if trajectory is valid:\n",
    "    check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "    # intialize the optimal learning parameters for 2-qubits\n",
    "    learning_rate_qbm = .5\n",
    "    maxiter_qbm = 2**11\n",
    "\n",
    "    #only relevant for checking if the mapping is inverisble\n",
    "    learning_rate_bm = .8\n",
    "    maxiter_bm = 2**20\n",
    "\n",
    "    # specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "    qm_params_to_plot = None\n",
    "    # qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "    threshold = 0.1  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "    # call the function and plot the results\n",
    "    quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "    plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23bff71a",
   "metadata": {},
   "source": [
    "(Partial?) 4 bit fully connected [square w/o diagonals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edde2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run =  0 #skip this due to long computation time\n",
    "if run == 1: \n",
    "    # initialize the parameters\n",
    "    N = 4\n",
    "    w = np.array([[3, 3 ,3, 3],\n",
    "                  [3, 3, 3, 3],\n",
    "                  [3, 3, 3, 3],\n",
    "                  [3, 3, 3, 3]], dtype = np.float64)\n",
    "\n",
    "    #only have the 2-3 diagonal\n",
    "    J = np.array([[0, 1, 1, 0],\n",
    "                  [1 ,0, 1, 1],\n",
    "                  [1 ,1, 0, 1],\n",
    "                  [0, 1, 1, 0]],    dtype = np.float64)\n",
    "\n",
    "    h = np.array([1e-7, 1e-7, 1e-7, 1e-7],dtype = np.float64)\n",
    "    check_parameters(w,J,h)\n",
    "\n",
    "    # define the start, end and step size for the parameter change\n",
    "    start = -.9\n",
    "    end = .9\n",
    "    steps = 3\n",
    "\n",
    "    # define the parameter and index you want to change\n",
    "    param = 'J'\n",
    "    index = (0, 1)\n",
    "\n",
    "    #check the inversion error to see if trajectory is valid:\n",
    "    check_inversion_error_forward(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm, learning_rate_bm, maxiter_bm)\n",
    "\n",
    "    # intialize the optimal learning parameters for 2-qubits\n",
    "    learning_rate_qbm = .5\n",
    "    maxiter_qbm = 2**11\n",
    "\n",
    "    #only relevant for checking if the mapping is inverisble\n",
    "    learning_rate_bm = .8\n",
    "    maxiter_bm = 2**20\n",
    "\n",
    "    # specify the quantum parameters to plot, if you select none, all that change more than the threshold over the sweep will be plotted\n",
    "    qm_params_to_plot = None\n",
    "    # qm_params_to_plot = ['$J_{12}^{XX}$', '$J_{12}^{YY}$', '$J_{12}^{ZZ}$'] \n",
    "    threshold = 0.1  #minimal change over sweep for the parameters to be plotted\n",
    "\n",
    "    # call the function and plot the results\n",
    "    quantum_params = analyze_forward_parameter_mapping(start, end, steps, param, index, w, J, h, learning_rate_qbm, maxiter_qbm)\n",
    "    plot_forward_mapping(quantum_params, start, end, steps, param, index, w, J, h, N, qm_params_to_plot, threshold, print_initial_config = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d83517b",
   "metadata": {},
   "source": [
    "## Inverse Mapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59f36c26",
   "metadata": {},
   "source": [
    "We can’t do the entire mapping backward because the quantum model is a ‘richer’ model, even just with two-body interactions. Due to the nature of the density matrix. This is already hinted at in the forward mapping, where the quantum model is capable of encoding dynamical effects that the BM is ‘blind’ to.  Even if you have only 2-body interactions in your QM hamiltonian, if you expand it in a matrix, you can still have higher order terms:\n",
    "\n",
    "$$\\rho = e^{\\hat{H}} = 1 + \\hat{H} + \\frac{1}{2!} \\hat{H}^2 + \\frac{1}{3!} \\hat{H}^3 + \\frac{1}{4!} \\hat{H}^4 + ...$$\n",
    "\n",
    "This is why we can't expect the inverse mapping to work for most cases.\n",
    "\n",
    "$$W^* = \\sqrt{p} \\hat{\\rho} \\frac{1}{\\sqrt{p}}$$\n",
    "$$W  = W(s \\mid s) \\delta_{s^{\\prime}, s} + \\sum_{i} g_{i}(s) \\delta_{s^{\\prime}, F_{i}[s]} +  \\sum_{ij} g_{ij}(s) \\delta_{s^{\\prime}, F_{ij}[s]}$$  \n",
    "$$W^* \\neq W$$\n",
    "\n",
    "What we can do however, is obtain a transition matrix from the quantum Hamiltonian and analyze it using different methods than a BM, for example by simulating it.  Use small enough QM paramaters otherwise there will be non-normalized probabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1203cc43",
   "metadata": {},
   "source": [
    "### Model in this way is not complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "#Leave out the terms containing odd amounts of Y\n",
    "interaction_weights[('I', 'I')] =  0\n",
    "\n",
    "#hx1 > Jxz\n",
    "interaction_weights[('I', 'X')] = .8   #hx1\n",
    "interaction_weights[('X', 'Z')] = .5   #Jxz\n",
    "\n",
    "#hx2 > Jzx\n",
    "interaction_weights[('X', 'I')] = .6   #hx2\n",
    "interaction_weights[('Z', 'X')] = .4   #Jzx\n",
    "\n",
    "# Jxx > Jyy\n",
    "interaction_weights[('X', 'X')] = .6   #Jxx\n",
    "interaction_weights[('Y', 'Y')] = .4   #Jyy\n",
    "\n",
    "# all Z-only terms < 1\n",
    "interaction_weights[('I', 'Z')] = .1   #hz1\n",
    "interaction_weights[('Z', 'I')] = .1   #hz2\n",
    "interaction_weights[('Z', 'Z')] = .4   #Jzz\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the full dynamics\n",
    "N = 2\n",
    "steps = 2000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J, h, title = 'Full dynamics', print_inferred_params = True)\n",
    "\n",
    "#plot the dynamics inferred by the Boltzmann machine\n",
    "W_bm = compute_transition_matrix(w, h, J)\n",
    "trajectory_bm = simulate_dynamics(W_bm, steps, N)\n",
    "plot_combined_dynamics(trajectory_bm, N, w_qm, w, J, h, title= 'BM inferred dynamics', print_inferred_params = True)\n",
    "\n",
    "print(W - W_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1607a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 3\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "#Leave out the terms containing odd amounts of Y\n",
    "interaction_weights[('I', 'I', 'I')] = 0    #log(Z)\n",
    "\n",
    "#hxi > Jxzij + jxzik\n",
    "interaction_weights[('X', 'I', 'I')] = .5   #hx1\n",
    "interaction_weights[('X', 'Z', 'I')] = .1   #Jxz12\n",
    "interaction_weights[('X', 'I', 'Z')] = .2   #Jxz13\n",
    "\n",
    "interaction_weights[('I', 'X', 'I')] = .4   #hx2\n",
    "interaction_weights[('I', 'X', 'Z')] = .1   #Jxz23\n",
    "interaction_weights[('Z', 'X', 'I')] = .1   #Jzx12\n",
    "\n",
    "interaction_weights[('I', 'I', 'X')] = .8   #hx3\n",
    "interaction_weights[('I', 'Z', 'X')] = .2   #Jzx23\n",
    "interaction_weights[('Z', 'I', 'X')] = .3   #Jzx13\n",
    "\n",
    "\n",
    "# Jxx > Jyy\n",
    "interaction_weights[('X', 'X', 'I')] = .6   #Jxx12\n",
    "interaction_weights[('Y', 'Y', 'I')] = .4   #Jyy12\n",
    "\n",
    "interaction_weights[('I', 'X', 'X')] = .7   #Jxx23\n",
    "interaction_weights[('I', 'Y', 'Y')] = .4   #Jyy23\n",
    "\n",
    "interaction_weights[('X', 'I', 'X')] = .8   #Jxx13\n",
    "interaction_weights[('Y', 'I', 'Y')] = .4   #Jyy13\n",
    "\n",
    "\n",
    "# all Z-only terms < 1\n",
    "interaction_weights[('Z', 'I', 'I')] = .1   #hz1\n",
    "interaction_weights[('I', 'Z', 'I')] = .1   #hz2\n",
    "interaction_weights[('I', 'I', 'Z')] = .1   #hz3\n",
    "\n",
    "interaction_weights[('Z', 'Z', 'I')] = .3   #Jzz12\n",
    "interaction_weights[('Z', 'I', 'Z')] = .3   #Jzz13\n",
    "interaction_weights[('I', 'Z', 'Z')] = .3   #Jzz23\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the full dynamics\n",
    "N = 3\n",
    "steps = 200\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J, h, title = 'Full dynamics', print_inferred_params = False, print_only_nonzero = True)\n",
    "\n",
    "#plot the dynamics inferred by the Boltzmann machine\n",
    "W_bm = compute_transition_matrix(w, h, J)\n",
    "trajectory_bm = simulate_dynamics(W_bm, steps, N)\n",
    "plot_combined_dynamics(trajectory_bm, N, w_qm, w, J, h, title = 'BM dynamics', print_inferred_params = False, print_only_nonzero = True)\n",
    "\n",
    "print(W - W_bm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "321ca4b8",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Classical (z-direction) couplings are connected to equilibrium statistics  \n",
    "- Non-classical couplings show dynamical effects   \n",
    "- Check the eigenvalue gap between W and W* (diff between max eigenvalues)  \n",
    "- Check XZ and YZ couplings.\n",
    "- Check what happens when you use 3rd body interactions in the QM hamiltonian\n",
    "- Interpret wyy, wxx terms.\n",
    "- Investigate non-zero 3 body interactions in QM Hamiltonian\n",
    "- What quantum information do we lose when transfering it to a classical object?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edd4bf5a",
   "metadata": {},
   "source": [
    "### 2-Qubits Result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ed713a0",
   "metadata": {},
   "source": [
    "#### Influence of $h^x$ term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e967b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "# set only Jxx to non-zero\n",
    "interaction_weights[('X', 'I')] = 0.05   #Jxx\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $h_{1}^{x}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "# set only Jxx to non-zero\n",
    "interaction_weights[('I', 'X')] = 0.05   #Jxx\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $h_{2}^{x}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d067f9d3",
   "metadata": {},
   "source": [
    "#### Influence of $h^z$ term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "interaction_weights[('Z', 'I')] =  -0.06\n",
    "interaction_weights[('I', 'X')] =  0.02\n",
    "interaction_weights[('X', 'I')] =  0.02\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $h_{1}^{Z}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "interaction_weights[('I', 'Z')] =  0.06\n",
    "interaction_weights[('I', 'X')] =  0.02\n",
    "interaction_weights[('X', 'I')] =  0.02\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $h_{2}^{Z}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c04ab93",
   "metadata": {},
   "source": [
    "#### Influence of $J^{xx}$ term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "# set only Jxx to non-zero\n",
    "interaction_weights[('X', 'X')] = 0.05   #Jxx\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $J_{12}^{XX}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75761917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "# set only Jxx to non-zero\n",
    "interaction_weights[('X', 'X')] = .35   #Jxx\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $J_{12}^{XX}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f695aae",
   "metadata": {},
   "source": [
    "#### Influence of $J^{yy}$ term"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a723f574",
   "metadata": {},
   "source": [
    "It appears that Jyy also models the affinity of a certain spin flip, not just the rate. Can't seem to get the separated time scale plot. Try again later because it would be really cool to have. Make the Jyy hypothesis more concrete. What exactly does Jyy encode? It appears to have to do with the synchronity for certain, but so also with the affinity?\n",
    "\n",
    "- Plot the sum of Jxx and Jyy and also the difference\n",
    "Jyy is zero when classical J is zero. \n",
    "\n",
    "odd states = -1 product of spins\n",
    "\n",
    "even states = 1 product of spins\n",
    "\n",
    "What really is the difference between Jx and Jy encoding the flipping synchronisation and Jz doing it? \n",
    "Updated hypothesis: Jzz encodes the synchronization between the spins due to toplogical connection. Jxx + Jyy encode the synchronization due to external effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "# Jxx > Jyy\n",
    "interaction_weights[('X', 'X')] = 0.1 #Jxx\n",
    "interaction_weights[('Y', 'Y')] = -0.1  #Jyy\n",
    "# interaction_weights[('Z', 'Z')] = -0.1  #Jzz\n",
    "interaction_weights[('X', 'I')] = 0.01  #hx1\n",
    "# interaction_weights[('I', 'X')] = 0.01  #hx2\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 100\n",
    "trajectory = simulate_dynamics(W, steps, N, s = np.array([1,-1]))\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $J_{12}^{YY}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "789a3511",
   "metadata": {},
   "source": [
    "#### Influence of $J^{zz}$ term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e37a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "interaction_weights[('X', 'I')] = 0.05\n",
    "interaction_weights[('I', 'X')] = 0.05\n",
    "interaction_weights[('Z', 'Z')] = -0.25   #Jzz\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "s = np.array([-1, -1]) #initial configuration\n",
    "trajectory = simulate_dynamics(W, steps, N, s)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $J_{12}^{ZZ}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dd9dcb3",
   "metadata": {},
   "source": [
    "#### Influence of $J^{xz}$ and $J^{zx}$ terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a70b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "#hx1 > Jxz\n",
    "interaction_weights[('X', 'I')] = 0.04   #hx1\n",
    "interaction_weights[('I', 'X')] = 0.04   #hx2\n",
    "interaction_weights[('X', 'Z')] = -0.035   #Jxz\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $J_{12}^{XZ}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "#hx2 > Jzx\n",
    "interaction_weights[('X', 'I')] = 0.04   #hx1\n",
    "interaction_weights[('I', 'X')] = 0.04   #hx2\n",
    "interaction_weights[('Z', 'X')] = 0.035 #Jxzz\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $J_{12}^{ZX}$ on dynamics', print_inferred_params = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0abd2ddf",
   "metadata": {},
   "source": [
    "### Three-body interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8365604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 3\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "#hx2 > Jzx\n",
    "interaction_weights[('X', 'X', 'X')] = 0.05   \n",
    "# interaction_weights[('X', 'I', 'I')] = 0.001   #hx1\n",
    "# interaction_weights[('I', 'X', 'I')] = 0.001   #hx2\n",
    "# interaction_weights[('I', 'I', 'X')] = 0.001   #hx3\n",
    "\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 3\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $\\sigma_{123}^{XXX}$ on dynamics', print_inferred_params = False, print_only_nonzero = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 3\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "#hx2 > Jzx\n",
    "interaction_weights[('X', 'X', 'X')] = 0.06  \n",
    "# interaction_weights[('X', 'Y', 'Y')] = -0.05\n",
    "# interaction_weights[('X', 'I', 'I')] = 0.04   #hx1\n",
    "# interaction_weights[('I', 'X', 'I')] = 0.04   #hx2\n",
    "# interaction_weights[('I', 'I', 'X')] = 0.04   #hx3\n",
    "\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 3\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N, s =np.array([-1,-1,-1]))\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $\\sigma_{123}^{XYY}$ on dynamics', print_inferred_params = False, print_only_nonzero = True)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0742701a",
   "metadata": {},
   "source": [
    "### Higher order YYYY couplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 4\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "#hx2 > Jzx\n",
    "interaction_weights[('X', 'X', 'X', 'X')] = 0.08\n",
    "interaction_weights[('Y', 'Y', 'Y', 'Y')] = 0.07\n",
    "# interaction_weights[('X', 'I', 'I', 'I')] = 0.01   #hx1\n",
    "# interaction_weights[('I', 'X', 'I', 'I')] = 0.01   #hx2\n",
    "# interaction_weights[('I', 'I', 'X', 'I')] = 0.01   #hx3\n",
    "# interaction_weights[('I', 'I', 'I', 'X')] = 0.01   #hx4\n",
    "\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = False)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 4\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N, s = np.array([-1,-1, 1, 1]))\n",
    "plot_combined_dynamics(trajectory, N, w_qm, w, J , h, title = 'Influence of $\\sigma_{1234}^{YYYY}$ on dynamics', print_inferred_params = False, print_only_nonzero = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_detailed_balance(W):\n",
    "    \"\"\"\n",
    "    Check if the transition matrix W and stationary distribution pi satisfy the detailed balance condition.\n",
    "    \"\"\"\n",
    "    pi = steady_state(W)\n",
    "    n_states = W.shape[0]\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            assert np.isclose(W[i, j] * pi[i], W[j, i] * pi[j]), \"Transition matrix does not satisfy detailed balance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f8a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classical parameters\n",
    "N = 2\n",
    "w = np.array([[8,9],\n",
    "              [9,8]], dtype=np.float64)\n",
    "J = np.array([[1,4],\n",
    "              [4,2]], dtype=np.float64)\n",
    "h = np.array([0, 2],  dtype=np.float64)\n",
    "\n",
    "W = compute_transition_matrix(w,h,J)\n",
    "\n",
    "check_detailed_balance(W)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2de304c",
   "metadata": {},
   "source": [
    "We hypothesise that the assymetric part of the transition matrix maps to the imaginary components of the density matrix. We can check this by looking at the assymetric part of the transition matrix and see if it maps to the imaginary components of the density matrix.\n",
    "\n",
    "We can do so as follows:\n",
    "\n",
    "$\\Pi = diag(p(s))$  \n",
    "$F = \\Pi W$   Corresponds to probability flux, rewritten in terms of the transition matrix:\n",
    "$W = \\Pi^{-1} F$\n",
    "We can split the flux in a symmetric and assymetric part:  \n",
    "$F_{S} = \\frac{F + F^T}{2} , F_{A} = \\frac{F - F^T}{2} $  \n",
    "Which we can rewrite in terms of the symmetric and antisymmetric transition matrix:\n",
    "$W_{S} = \\Pi^{-1} F_{S}, W_{A} = \\Pi^{-1} F_{A}$  \n",
    "\n",
    "$W_{S} = \\Pi^{-1} \\frac{F + F^T}{2} = \\frac{\\Pi^{-1} F + \\Pi^{-1} F^T}{2} = \\frac{W + \\Pi W^{T} \\Pi^{-1}}{2}$\n",
    "\n",
    "With $F^T = (W \\Pi)^T = \\Pi^T W^T = \\Pi W^T$\n",
    "  \n",
    "Combining these results, we can write\n",
    "$W_{S/A} = \\left[\\frac{W \\pm \\Pi W^{T} \\Pi^{-1}}{2}\\right]$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1044275",
   "metadata": {},
   "source": [
    "Splitting W into a symmetric and assymetric part. Maybe we can split into a symmetric part and assymetric part and individually see to which QM parameters these transition matrices map back. In the symmetric case, we can also map it back to classical parameters.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7807dea0",
   "metadata": {},
   "source": [
    "\n",
    "We know that that the odd y-terms of the QM hamiltonian map to imaginary parts. So if we can find this link, we can link the odd y-terms to a dynamics that does not satisfy detailed balance, which would be interesting. Then we know other qm-parameters that map to dynamical classical parameters.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a02f6b11",
   "metadata": {},
   "source": [
    "### 3 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 3\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "#Leave out the terms containing odd amounts of Y\n",
    "interaction_weights[('I', 'I', 'I')] = 0    #log(Z)\n",
    "\n",
    "#hxi > Jxzij + jxzik\n",
    "interaction_weights[('X', 'I', 'I')] = .5   #hx1\n",
    "interaction_weights[('X', 'Z', 'I')] = .1   #Jxz12\n",
    "interaction_weights[('X', 'I', 'Z')] = .2   #Jxz13\n",
    "\n",
    "interaction_weights[('I', 'X', 'I')] = .4   #hx2\n",
    "interaction_weights[('I', 'X', 'Z')] = .1   #Jxz23\n",
    "interaction_weights[('Z', 'X', 'I')] = .1   #Jzx12\n",
    "\n",
    "interaction_weights[('I', 'I', 'X')] = .8   #hx3\n",
    "interaction_weights[('I', 'Z', 'X')] = .2   #Jzx23\n",
    "interaction_weights[('Z', 'I', 'X')] = .3   #Jzx13\n",
    "\n",
    "\n",
    "# Jxx > Jyy\n",
    "interaction_weights[('X', 'X', 'I')] = .6   #Jxx12\n",
    "interaction_weights[('Y', 'Y', 'I')] = .4   #Jyy12\n",
    "\n",
    "interaction_weights[('I', 'X', 'X')] = .7   #Jxx23\n",
    "interaction_weights[('I', 'Y', 'Y')] = .4   #Jyy23\n",
    "\n",
    "interaction_weights[('X', 'I', 'X')] = .8   #Jxx13\n",
    "interaction_weights[('Y', 'I', 'Y')] = .4   #Jyy13\n",
    "\n",
    "\n",
    "# all Z-only terms < 1\n",
    "interaction_weights[('Z', 'I', 'I')] = .1   #hz1\n",
    "interaction_weights[('I', 'Z', 'I')] = .1   #hz2\n",
    "interaction_weights[('I', 'I', 'Z')] = .1   #hz3\n",
    "\n",
    "interaction_weights[('Z', 'Z', 'I')] = .3   #Jzz12\n",
    "interaction_weights[('Z', 'I', 'Z')] = .3   #Jzz13\n",
    "interaction_weights[('I', 'Z', 'Z')] = .3   #Jzz23\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a80b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the weights using the dictionary\n",
    "num_qubits = 2\n",
    "interaction_matrices,interaction_labels,interaction_weights = generate_interaction_matrices(num_qubits)\n",
    "\n",
    "#Leave out the terms containing odd amounts of Y\n",
    "interaction_weights[('I', 'I')] =  0\n",
    "\n",
    "#hx1 > Jxz\n",
    "interaction_weights[('X', 'I')] = 0   #hx1\n",
    "interaction_weights[('X', 'Z')] = 0   #Jxz\n",
    "\n",
    "#hx2 > Jzx\n",
    "interaction_weights[('I', 'X')] = 0   #hx2\n",
    "interaction_weights[('Z', 'X')] = 0   #Jzx\n",
    "\n",
    "# Jxx > Jyy\n",
    "interaction_weights[('X', 'X')] = 0.05 #Jxx\n",
    "interaction_weights[('Y', 'Y')] = 0    #Jyy\n",
    "\n",
    "# all Z-only terms < 1\n",
    "interaction_weights[('I', 'Z')] = 0   #hz1\n",
    "interaction_weights[('Z', 'I')] = 0   #hz2\n",
    "interaction_weights[('Z', 'Z')] = 0   #Jzz\n",
    "\n",
    "# make sure there are no imaginary components\n",
    "interaction_weights = set_odd_y_interactions_to_zero(interaction_labels, interaction_weights)\n",
    "\n",
    "#qm hamiltonian to density matrix\n",
    "w_qm = weights_dict_to_array(interaction_labels, interaction_weights) \n",
    "\n",
    "# perform inverse mapping\n",
    "W, w, J, h = inverse_mapping(w_qm, learning_rate_bm, maxiter_bm, plot_convergence = False, perform_checks = True)\n",
    "\n",
    "#plot the dynamics\n",
    "N = 2\n",
    "steps = 1000\n",
    "trajectory = simulate_dynamics(W, steps, N)\n",
    "plot_combined_dynamics(trajectory, N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
